<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex">
    <title>インタラクティブ学習カリキュラム</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Visualization & Content Choices:
        - Curriculum Structure (Chapters/Units): Goal: Organize & Navigate. Method: Interactive sidebar (JS for click events, dynamic content loading), main content display area. Interaction: Click to select chapter/unit, click to expand/collapse sections. Justification: Follows standard e-learning UX, easy to scan and drill down. Library/Method: HTML, Tailwind, Vanilla JS.
        - Unit Details (Goal, Topics, Explanation, Hint): Goal: Inform. Method: Structured text blocks using headings, lists, paragraphs. Topics/Explanation/Hint sections are collapsible using <details> and <summary>. Interaction: Click to expand/collapse. Justification: Improves readability by breaking down information. Library/Method: HTML, Tailwind, Vanilla JS.
        - Code Snippets (from Exercise Hints/Explanations): Goal: Illustrate. Method: Styled `<pre><code>` blocks. Interaction: None (static display). Justification: Clear presentation of code. Library/Method: HTML, Tailwind.
        - Sample Charts (for Matplotlib units): Goal: Illustrate. Method: Use Chart.js to render simple examples of bar, scatter, histogram based on Exercise Hints. Interaction: Static display. Justification: Provides visual context for Matplotlib exercises without requiring external execution. Library/Method: Chart.js, Vanilla JS for data setup.
        - CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body { font-family: 'Inter', sans-serif; }
        .sidebar {
            min-width: 280px;
            width: 25%;
            max-width: 320px;
        }
        .main-content {
            width: 75%;
        }
        details > summary {
            cursor: pointer;
            list-style: none; /* Firefox */
        }
        details > summary::-webkit-details-marker {
            display: none; /* Chrome/Safari */
        }
        details > summary::before {
            content: '▶ ';
            font-size: 0.8em;
            margin-right: 0.3rem;
        }
        details[open] > summary::before {
            content: '▼ ';
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 300px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            border-left: 3px solid #4A90E2;
            color: #333;
            page-break-inside: avoid;
            font-family: monospace;
            font-size: 15px;
            line-height: 1.6;
            margin-bottom: 1.6em;
            max-width: 100%;
            overflow: auto;
            padding: 1em 1.5em;
            display: block;
            word-wrap: break-word;
            border-radius: 0.375rem;
        }
    </style>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Noto+Sans+JP:wght@400;700&display=swap" rel="stylesheet">
</head>
<body class="bg-stone-100 text-stone-800 flex flex-col min-h-screen" style="font-family: 'Noto Sans JP', sans-serif;">

    <header class="bg-teal-700 text-white p-4 shadow-md sticky top-0 z-50">
        <h1 class="text-2xl font-bold">インタラクティブ学習カリキュラム 📖</h1>
    </header>

    <div class="flex flex-1 overflow-hidden">
        <nav id="sidebar" class="sidebar bg-stone-200 p-5 overflow-y-auto h-[calc(100vh-64px)] sticky top-[64px]">
            <ul id="curriculum-nav" class="space-y-2"></ul>
        </nav>

        <main id="main-content-area" class="main-content p-8 overflow-y-auto h-[calc(100vh-64px)]">
            <div id="content-placeholder">
                <h2 class="text-3xl font-bold text-teal-700 mb-4">ようこそ！</h2>
                <p class="text-lg">左のナビゲーションから学習したい章やユニットを選択してください。</p>
                <p class="mt-2">このアプリケーションは、提供された学習カリキュラムをインタラクティブに探索するためのものです。各章の概要やユニットごとの詳細な学習内容（目標、主要トピック、解説、演習のヒント）を効率的に確認できます。</p>
            </div>
        </main>
    </div>

<script>
const curriculumData = {
    introduction: {
        title: "はじめに",
        content: `このカリキュラムは、Jupyter Notebookの操作から始め、Pythonプログラミングの基礎、そして数学・機械学習ライブラリであるpandas, NumPy, Matplotlib, scikit-learn, PyTorchの基本的な使い方を段階的に習得することを目的としています。各章は複数の単元で構成され、1単元あたり約15分で完了できるように設計されています。このカリキュラムを通じて、データサイエンスと機械学習の実践的なスキルを身につけるための強固な土台を構築します。OSはWindowsを前提とし、Jupyter Notebookはインストール済みであるとします。`
    },
    chapters: [
        {
            title: "第1章: Jupyter Notebookの使い方",
            summary: "この章では、データサイエンスプロジェクトの対話的な開発と提示に非常に強力なツールであるJupyter Notebookの基本的な使い方を学びます。Jupyter Notebookは、コード、視覚化、説明文、その他のリッチメディアを単一のドキュメントに組み合わせることで、一貫性のある表現豊かなワークフローを作成します。この章を通じて、ノートブックの作成、セルの操作、Markdown記法、カーネル管理など、Jupyter Notebookを効果的に使用するための基礎を習得します。",
            units: [
                { title: "Unit 1.1: Jupyter Notebookとは？", goal: "Jupyter Notebookの概要、特徴、利点を理解する。", topics: ["Jupyter Notebookの定義：対話型コンピューティング環境 [1]。", "主な特徴：コード、テキスト、数式、視覚化を混在可能 。", "利点：試行錯誤の容易さ、結果の再現性、教育・プレゼンテーションへの活用 [1]。", "データサイエンスにおける役割：データの探索、分析、モデル開発、結果共有 。"], explanation: "Jupyter Notebookは、ライブコード、方程式、視覚化、説明テキストを含むドキュメントを作成し共有できるオープンソースのウェブアプリケーションです 。データサイエンティストがデータをクリーンアップし、変換し、数値シミュレーションを実行し、統計モデリングを行い、機械学習モデルを訓練し、その結果を共有するための包括的なプラットフォームを提供します。特に対話的にコードを実行し、その結果を即座に確認できるため、探索的データ分析やアルゴリズムの試行錯誤に適しています。", exerciseHint: "Jupyter Notebookで作成された優れた分析レポートの例をオンラインで検索し、どのような要素で構成されているか観察する。" },
                { title: "Unit 1.2: Jupyter Notebookの起動と画面構成", goal: "Jupyter Notebookを起動し、基本的な画面構成を理解する。", topics: ["Windowsでの起動方法：Anaconda Navigator経由、またはコマンドプロンプト/Anaconda Promptで `jupyter notebook` と入力 [1, 3]。", "起動後のダッシュボード画面：ファイルブラウザ、ディレクトリ構造の表示 。", "主要なUI要素：`New`ボタン（新規ノートブック作成、フォルダ作成など）、`Upload`ボタン 。", "ノートブックファイル (`.ipynb`ファイル) の概念 [1]。"], explanation: "Jupyter Notebookを起動すると、デフォルトのウェブブラウザでダッシュボードが開きます [1]。このダッシュボードは、ファイルやフォルダを管理するインターフェースです。ここから新しいノートブックを作成したり、既存のノートブックを開いたり、新しいフォルダを作成したりできます [3]。各ノートブックは `.ipynb` という拡張子のファイルとして保存され、これはノートブックの内容をJSON形式で記述したテキストファイルです [1]。このファイル形式により、ノートブックの共有やバージョン管理が容易になります。", exerciseHint: "Jupyter Notebookを起動し、ダッシュボード画面で新しいフォルダを作成し、そのフォルダ内に移動する。" },
                { title: "Unit 1.3: セルの種類と基本操作", goal: "Jupyter Notebookの主要なセルタイプ（コードセル、Markdownセル）とその基本的な使い方を理解する。", topics: ["セルの概念：コードやテキストを記述するブロック [1]。", "コードセル (Code Cell)：Pythonコード（または他のサポート言語のコード）を実行するためのセル [1]。\n    - 簡単なコードの入力と実行 (`Run`ボタンまたは `Ctrl + Enter`)。\n    - `In [ ]:` (入力) と `Out [ ]:` (出力) の表示の意味 [1]。", "Markdownセル (Markdown Cell)：Markdown記法を使って整形されたテキストや説明文を記述するためのセル [1]。\n    - 簡単なMarkdownテキストの入力とレンダリング。"], explanation: "Jupyter Notebookの中心的な要素は「セル」です。セルには主に「コードセル」と「Markdownセル」の2種類があります [1]。コードセルには実行可能なコードを記述し、実行するとその結果がセルの直下に表示されます。例えば、`print('Hello World!')` と入力して実行すると、`Hello World!` という出力が得られます [1]。Markdownセルには、見出し、リスト、太字、リンクなどを含む整形されたテキストを記述でき、実行するとHTMLとしてレンダリングされます。この2つのセルを組み合わせることで、分析コードとその説明、結果を一体化したドキュメントを作成できます。新しいノートブックの最初のセルはデフォルトでコードセルになっています [1]。", exerciseHint: "新しいノートブックを作成し、コードセルに `1 + 1` と入力して実行する。次に、新しいセルをMarkdownセルに変更し、`# これは見出しです` と入力して実行する。" },
                { title: "Unit 1.4: ノートブックの操作 (ファイル操作、セル操作)", goal: "ノートブックの保存、セルの追加・削除・移動などの基本的な操作を習得する。", topics: ["ファイル操作：\n    - 新規ノートブックの作成 (`File` > `New Notebook` またはダッシュボードから)。\n    - ノートブックの保存 (ツールバーの保存アイコン、`Ctrl + S`) [4]。\n    - ノートブックの複製、名前の変更、削除 (ダッシュボード画面でファイルを選択して操作) [4]。", "セル操作 (主にツールバーを使用)：\n    - セルの追加 (選択セルの上下に挿入) [4]。\n    - セルの削除 [4]。\n    - セルのコピーと貼り付け [4]。\n    - セルの移動 (上下) [4]。\n    - 選択セルの実行 [4]。\n    - セルタイプの変更 (Code, Markdownなど) [4]。"], explanation: "Jupyter Notebookのツールバーには、ノートブックやセルを操作するための様々なボタンが用意されています [4]。例えば、フロッピーディスクのアイコンでノートブックを保存したり、プラス記号のアイコンで新しいセルを追加したりできます。選択したセルを削除、コピー、貼り付けする機能や、セルの順番を上下に入れ替える機能もツールバーからアクセスできます。これらの操作を覚えることで、ノートブックの編集がスムーズに行えるようになります。", exerciseHint: "複数のセル（コードセルとMarkdownセルを混在）を作成し、セルの追加、削除、コピー、移動、保存といった一連の操作をツールバーを使って行う。" },
                { title: "Unit 1.5: Markdown記法入門", goal: "Jupyter Notebook内で説明文やドキュメントを記述するために、基本的なMarkdown記法を習得する。", topics: ["Markdownとは：軽量マークアップ言語。", "見出し：`#` の数でレベルを指定 (例: `# H1`, `## H2`)。", "リスト：番号なしリスト (`-`, `*`)、番号付きリスト (`1.`, `2.`)。", "文字装飾：太字 (`**text**` or `__text__`)、イタリック (`*text*` or `_text_`)。", "リンク：`[表示テキスト](URL)`。", "(補足) LaTeXによる数式表現：`$formula$` (インライン)、`$$formula$$` (ディスプレイ) [2]。"], explanation: "Markdownは、プレーンテキストで書かれた文書からHTMLなどの形式に変換するために設計された軽量マークアップ言語です。Jupyter NotebookのMarkdownセルでは、このMarkdown記法を用いて、分析コードに対する説明、考察、レポートなどを記述することができます [2, 5]。見出しを使って文書構造を明確にしたり、リストを使って情報を整理したり、太字やイタリックで特定の語句を強調したりすることが容易に行えます。また、数式を記述するためのLaTeXもサポートされており [2]、科学技術計算のレポート作成にも適しています。Markdownを効果的に使用することで、コードだけでなく、その背景や解釈も含む、非常に分かりやすいノートブックを作成できます。これは、データサイエンティストが分析のストーリーを語る上で重要なスキルとなります [2]。", exerciseHint: "Markdownセルに見出し、リスト（番号なし・番号付き）、太字・イタリックのテキスト、簡単な数式（例: $E=mc^2$）を含む説明文を作成する。" },
                { title: "Unit 1.6: カーネルの役割と管理", goal: "カーネルの役割を理解し、再起動や割り込みなどの基本的な管理操作を行えるようになる。", topics: ["カーネルとは：「計算エンジン」、コードを実行する脳 [1]。", "カーネルの主な操作 (Kernelメニューまたはツールバーから)：\n    - Interrupt (実行中のセルを停止) [4]。\n    - Restart (カーネルを再起動し、変数をリセット) [4]。\n    - Restart & Clear Output (カーネルを再起動し、全セルの出力をクリア)。\n    - Restart & Run All (カーネルを再起動し、全セルを先頭から順に実行)。", "カーネルがビジー状態のときの表示 (例: アスタリスク `In [*]:`)。"], explanation: "Jupyter Notebookにおけるカーネルは、実際にコードを実行する「計算エンジン」です [1]。ノートブックでコードセルを実行すると、そのコードがカーネルに送られ、カーネルが計算処理を行い、結果を返します。長時間かかる計算の途中で処理を中断したい場合や、何らかの理由でカーネルが応答しなくなった場合には、「Interrupt」操作で実行を停止できます [4]。また、定義した変数やインポートしたライブラリの状態を一度リセットしたい場合には、「Restart」操作を行います [4]。これにより、カーネルは初期状態に戻ります。カーネルの適切な管理は、特に複雑な計算やデバッグを行う際に重要となり、ノートブックの動作の安定性と再現性を保つために不可欠です。", exerciseHint: "無限ループするようなコードセル（例: `while True: pass`）を実行し、Interrupt Kernelで停止してみる。変数をいくつか定義した後、Restart Kernelでそれらの変数がリセットされることを確認する。" },
                { title: "Unit 1.7: キーボードショートカットと効率的な操作", goal: "主要なキーボードショートカットを覚え、Jupyter Notebookの操作を効率化する。", topics: ["コマンドモード (青枠、`Esc`キーで移行) と編集モード (緑枠、`Enter`キーで移行) の切り替え [1]。", "コマンドモードでの操作：\n    - セルの上下移動 (`Up`/`Down`キー, または `J`/`K`キー) [1, 6]。\n    - セルの挿入 (`A`: 選択セルの上に挿入, `B`: 選択セルの下に挿入) [1, 6]。\n    - セルの削除 (`D`キーを2回) [6]。\n    - セルタイプ変更 (`M`: Markdownセルへ, `Y`: コードセルへ) [6]。", "編集モードでの操作：\n    - セルの実行 (`Ctrl + Enter`: その場で実行, `Shift + Enter`: 実行して下のセルへ移動または新規作成)。[1]", "その他の便利なショートカット (ツールバーのコマンドパレットで確認可能) [4]。"], explanation: "Jupyter Notebookには多数のキーボードショートカットが用意されており、これらを活用することでマウス操作を減らし、作業効率を大幅に向上させることができます [1, 6]。まず重要なのは、「コマンドモード」と「編集モード」の2つのモードの存在を理解することです。セルが青枠で選択されている状態がコマンドモードで、セル全体に対する操作（移動、コピー、削除、挿入など）を行います。セルが緑枠で、セル内にカーソルがある状態が編集モードで、セル内のコードやテキストを編集します。`Esc`キーでコマンドモードに、`Enter`キーで編集モードに移行します [1]。これらのショートカットを習熟することで、より迅速かつスムーズにノートブックを操作できるようになり、思考を中断することなく分析作業に集中できます。", exerciseHint: "ユニット1.4で学んだセル操作（追加、削除、コピー、移動、実行）を、キーボードショートカットのみで行ってみる。" },
                { title: "Unit 1.8: 簡単なデータ分析フロー体験", goal: "Jupyter Notebookを使って、簡単なデータ読み込み、処理、可視化という一連の流れを体験する。", topics: ["サンプルデータの準備 (簡単なPythonのリストや辞書からpandas DataFrameを作成する例を示す – pandasの詳細は第3章)。", "データの確認 (print文、DataFrameの `head()` メソッドなど)。", "簡単なデータ操作 (特定の列の選択、簡単な計算など)。", "Matplotlibを使った簡単なグラフ描画 (棒グラフや折れ線グラフの初歩 – Matplotlibの詳細は第5章)。", "Markdownセルでの考察の記述。"], explanation: "このユニットでは、これまでに学んだJupyter Notebookの機能を統合し、データ分析の非常に基本的な流れを体験します 。具体的には、少量のサンプルデータ（例えば、数日間の気温や簡単なアンケート結果を模したもの）をノートブック内で作成し、その内容を確認します。次に、データから平均値を計算するなどの簡単な処理を行い、その結果をMatplotlibライブラリ（詳細は後述）を使ってグラフで視覚化します。最後に、得られた結果やグラフについて、Markdownセルを用いて簡単な考察を記述します。この一連の作業を通じて、Jupyter Notebookがデータ分析の各段階（データの準備、処理、可視化、解釈、報告）をどのようにサポートするかを実感することができます。この体験は、後続の章で学ぶより高度なライブラリの必要性や有用性を理解する上で役立ちます。", exerciseHint: "身近な題材（例：1週間の勉強時間、好きな果物のアンケート結果など）で小さなデータセットをPythonのリストや辞書で作成し、簡単な集計（合計や平均など）を行い、その結果を簡単な棒グラフで表示し、結果に関する短いコメントをMarkdownで記述する、という一連の流れを試す。" }
            ]
        },
        {
            title: "第2章: Pythonの基礎",
            summary: "この章では、データサイエンスと機械学習の分野で広く使われるプログラミング言語であるPythonの基礎を学びます 。Pythonはその読みやすい構文と豊富なライブラリにより、データ分析、機械学習モデル構築、その他多くの科学技術計算タスクに最適な言語とされています [9, 10]。この章を通じて、変数、データ型、制御構造、関数といったプログラミングの基本的な概念をPythonで扱えるようになることを目指します。これらの知識は、続くpandasやNumPyなどの専門的なライブラリを学ぶ上での強固な土台となります。Pythonの学習しやすさと、データサイエンスに特化した強力なライブラリ群（NumPy, pandas, Matplotlib, scikit-learn, PyTorchなど）の存在は、互いに好影響を与え合い、Pythonをデータサイエンス分野における事実上の標準言語へと押し上げてきました [7, 8, 9]。このエコシステムは、より多くの開発者とライブラリを引きつけ続けています。",
            units: [
                { title: "Unit 2.1: Pythonとは？データサイエンスにおける役割", goal: "Python言語の概要と、データサイエンス分野で広く利用されている理由を理解する。", topics: ["Python言語の特徴：汎用性、高い可読性、豊富な標準ライブラリとサードパーティライブラリ [9, 11]。", "データサイエンスにおけるPython：データ収集、前処理、分析、可視化、機械学習モデル構築まで幅広く対応 。", "主要なデータサイエンスライブラリの紹介 (pandas, NumPy, Matplotlib, scikit-learn, PyTorchなど、後の章で詳述) [7, 9]。"], explanation: "Pythonは、Guido van Rossum氏によって開発された、シンプルで読みやすい構文を持つ汎用プログラミング言語です。その設計哲学はコードの可読性を重視しており、初心者にも比較的習得しやすいとされています [11]。データサイエンス分野では、データ処理ライブラリpandas、数値計算ライブラリNumPy、可視化ライブラリMatplotlib、機械学習ライブラリscikit-learn、深層学習フレームワークPyTorchといった強力なオープンソースライブラリがPython上で開発されており、これらがPythonの普及を大きく後押ししています 。これらのライブラリを活用することで、データ収集から分析、モデル構築、結果の報告まで、データサイエンスのワークフロー全体をPythonで一貫して行うことが可能です。Pythonとそのエコシステムのオープンソース性は、技術革新を促進し、学術界と産業界双方での広範な採用につながっています。", exerciseHint: "Pythonがデータサイエンス以外にどのような分野（例：Web開発、自動化、ゲーム開発など）で活用されているか、具体的な事例をウェブで検索してみる。" },
                { title: "Unit 2.2: 変数とデータ型 (数値、文字列、ブール値)", goal: "変数の概念を理解し、Pythonの基本的なデータ型（整数、浮動小数点数、文字列、ブール値）を扱えるようになる。", topics: ["変数：データを格納するための名前付きの入れ物 (例: `age = 30`)。", "データ型：\n    - 数値型：整数 (`int` 例: `10`, `-5`)、浮動小数点数 (`float` 例: `3.14`, `-0.5`) [8, 12]。\n    - 文字列型 (`str`)：テキストデータ。シングルクォート (`'...'`)またはダブルクォート (`\"...\"`)で囲む (例: `'hello'`, `\"world\"`) [8, 12]。\n    - ブール型 (`bool`)：真 (`True`) と偽 (`False`) の2つの値のみ [8, 12]。", "`type()`関数によるデータ型の確認 (例: `type(age)`)。"], explanation: "プログラミングにおいて、変数とはデータに名前を付けて保存しておくためのものです。Pythonでは、変数を使用する前に型を明示的に宣言する必要はなく（動的型付け）、代入された値に応じて自動的に型が決定されます。主要な基本データ型には、整数や小数を扱う数値型、文字の並びである文字列型、そして真偽値を表すブール型があります [8, 12]。これらのデータ型を理解し、適切に使い分けることは、プログラミングの基本です。Pythonの動的型付けは学習初期には簡便ですが、特にNumPyのような静的型付けを内部で利用するライブラリと連携する際には、意図しない型の不一致によるエラーを避けるため、データ型への注意が依然として重要です。", exerciseHint: "自分の名前（文字列）、年齢（整数）、身長（浮動小数点数、メートル単位）、プログラミング経験の有無（ブール値）を変数に代入し、それぞれの値を`print()`関数で表示し、`type()`関数で型を確認する。" },
                { title: "Unit 2.3: 基本的な演算 (算術演算、比較演算、論理演算)", goal: "Pythonの基本的な演算子（算術、比較、論理）を理解し、使用できるようになる。", topics: ["算術演算子：`+` (加算), `-` (減算), `*` (乗算), `/` (除算), `//` (整数除算、小数点以下切り捨て), `%` (剰余), `**` (べき乗) [13]。", "比較演算子：`==` (等しい), `!=` (等しくない), `>` (より大きい), `<` (より小さい), `>=` (以上), `<=` (以下)。結果はブール値 (`True` or `False`) [8, 12]。", "論理演算子：`and` (論理積), `or` (論理和), `not` (論理否定)。ブール値に対する操作 [8, 12]。", "演算子の優先順位 (例: 乗除算は加減算より先に行われる)。"], explanation: "Pythonでは、数値計算や条件判断のために様々な演算子が提供されています。算術演算子は四則演算やべき乗など、数学的な計算を行います [13]。比較演算子は2つの値を比較し、その結果をブール値（`True`または`False`）として返します。論理演算子は、ブール値同士を組み合わせて新たなブール値を作り出します [12]。これらの演算子は、データ分析におけるフィルタリング（特定の条件を満たすデータを選択する）や、プログラムの流れを制御する上で不可欠な要素です。例えば、pandasライブラリでデータフレームから特定の条件に合致する行を抽出する際には、比較演算子と論理演算子が頻繁に用いられます。", exerciseHint: "変数 `x = 10`, `y = 3` を定義し、これらの変数を使って様々な算術演算（和、差、積、商、整数商、剰余、べき乗）を行い結果を表示する。また、`x > 5 and y < 2` のような比較演算と論理演算を組み合わせた式の評価結果を確認する。" },
                { title: "Unit 2.4: データ構造1: リストとタプル (作成、インデックス、スライシング)", goal: "リストとタプルの作成方法、要素へのアクセス（インデックス参照、スライシング）を習得する。", topics: ["リスト (`list`)：順序付けられた、変更可能な要素の集まり。角括弧 `[]` で作成 (例: `my_list = [1, 'apple', 3.14]`)。\n    - 要素の追加 (`append()`, `insert()`)、削除 (`remove()`, `pop()`, `del`)、変更。\n    - インデックス参照：`list[i]` (0から始まる)。負のインデックスも可 (`list[-1]` は最後の要素)。\n    - スライシング：`list[start:end:step]` で部分リストを取得 [8, 12]。", "タプル (`tuple`)：順序付けられた、変更不可能な要素の集まり。丸括弧 `()` で作成 (例: `my_tuple = (1, 'banana', 2.71)`)。\n    - 作成後の要素の変更は不可。\n    - インデックス参照、スライシングはリストと同様に可能 [8, 12]。", "リストとタプルの使い分け：変更の必要性、データの不変性の保証。"], explanation: "リストとタプルは、複数の値をまとめて扱うための基本的なデータ構造です [8, 13]。リストは要素の変更、追加、削除が可能であるのに対し、タプルは一度作成するとその内容を変更できません（イミュータブル）。この性質の違いから、リストは動的に変化するデータの集まりに、タプルは固定的な値の組（例えば座標点など）に適しています。どちらもインデックス（要素の位置番号、0から始まる）を使って個々の要素にアクセスしたり、スライシングを使って一部分を取り出したりすることができます [12]。Pythonのリストは、NumPy配列やpandasのSeriesといった、より高度なデータ構造の元となるデータを一時的に格納するためにもよく利用されます [14]。", exerciseHint: "曜日の名前を格納したリストを作成し、最初の曜日、最後の曜日、2番目から4番目までの曜日をそれぞれ取り出して表示する。自分の名前と年齢を要素とするタプルを作成し、表示する。" },
                { title: "Unit 2.5: データ構造2: 辞書とセット (作成、基本操作)", goal: "辞書とセットの作成方法と基本的な操作（要素の追加、削除、参照）を習得する。", topics: ["辞書 (`dict`)：キー (key) と値 (value) のペアの集まり。波括弧 `{}` で作成 (例: `my_dict = {'name': 'Alice', 'age': 25}`)。Python 3.7以降では挿入順序が保持される。\n    - 要素の追加・更新：`dict[key] = value`。\n    - キーによる値の参照：`dict[key]`。存在しないキーを指定するとエラー。`get()`メソッドで安全にアクセス。\n    - キーの存在確認：`key in dict`。\n    - `keys()`, `values()`, `items()` メソッド。", "セット (`set`)：順序なしの、重複しない要素の集まり。波括弧 `{}` または `set()` 関数で作成 (例: `my_set = {1, 2, 3, 2}`)。\n    - 要素の追加 (`add()`)、削除 (`remove()`, `discard()`)。\n    - 集合演算：和 (`|`)、積 (`&`)、差 (`-`)。"], explanation: "辞書は、一意なキーとそれに対応する値をペアとして格納するデータ構造です [8, 13]。キーを使って効率的に値にアクセスできるため、設定情報やJSON形式のデータ（ウェブAPIでよく用いられる）など、構造化されたデータの表現に適しています。pandasのDataFrameは、辞書のリストや辞書そのものから容易に作成できます。セットは、重複を許さず、順序も持たない要素のコレクションです [8, 13]。セットは、ある要素がコレクション内に存在するかどうかの確認（メンバーシップテスト）や、コレクションから重複要素を削除するのに非常に効率的です。これらはデータの前処理段階で役立つ操作です。", exerciseHint: "果物の名前をキー、その価格を値とする辞書を作成する。いくつかの果物を追加し、特定の果物の価格を表示する。数値のリストから重複を取り除いたセットを作成し、表示する。" },
                { title: "Unit 2.6: 制御フロー1: 条件分岐 (if, elif, else)", goal: "`if`, `elif`, `else` を使った条件分岐処理を記述できるようになる。", topics: ["`if`文：指定した条件式が `True` の場合に、その直後のブロックの処理を実行。", "`else`文：`if`文（または先行する`elif`文）の条件式がすべて `False` の場合に実行する処理。", "`elif`文 (else if)：複数の条件を順番に評価し、最初に `True` となった条件のブロックを実行。", "インデント（字下げ）の重要性：Pythonではインデントでコードブロックを表現する。", "ネストされた条件分岐（`if`文の中にさらに`if`文を記述）。"], explanation: "条件分岐は、プログラムが状況に応じて異なる動作をするために不可欠な制御構造です [8, 13]。`if`文を用いることで、特定の条件が満たされたときだけ特定のコードを実行できます。`elif`（else ifの略）を使うと複数の条件を順番にチェックでき、`else`はその前のどの条件にも当てはまらなかった場合に実行される処理を記述します。これらの文は、データの値に基づいて処理を振り分けたり、エラー条件を判定したりする際に広く使われます。データ分析においては、データの特性に応じて異なる前処理を適用したり、分析結果に基づいて異なる結論を導き出したりするロジックを実装する際に、条件分岐が中心的な役割を果たします。", exerciseHint: "試験の点数（0〜100）を変数として持ち、その点数に応じて成績（例：90点以上なら「優」、80点以上90点未満なら「良」、70点以上80点未満なら「可」、70点未満なら「不可」）を判定し表示するプログラムを作成する。" },
                { title: "Unit 2.7: 制御フロー2: ループ (for, while)", goal: "`for`ループと`while`ループを使った繰り返し処理を記述できるようになる。", topics: ["`for`ループ：シーケンス（リスト、タプル、文字列など）やイテラブルオブジェクトの各要素に対して、順番に処理を繰り返す。\n    - `range()`関数との組み合わせ (例: `for i in range(5):`)。", "`while`ループ：指定した条件式が `True` である間、処理を繰り返す。", "ループ制御文：\n    - `break`：ループを途中で強制的に終了する。\n    - `continue`：現在のイテレーションの残りの処理をスキップし、次のイテレーションに進む。", "ループとインデント。"], explanation: "ループ処理は、同じまたは類似の操作を何度も繰り返す際に用いる基本的な制御構造です [8, 13]。`for`ループは、リストの各要素に対して処理を行ったり、指定した回数だけ処理を繰り返したりするのに適しています [12]。`while`ループは、特定の条件が満たされている間、処理を継続します。これらのループ構造は、データセットの各項目を処理したり、特定の条件が満たされるまで計算を繰り返したりする際に不可欠です。ただし、データサイエンスの文脈では、特に大きなデータセットに対しては、NumPyやpandasが提供するベクトル化された操作（ループを内部的にC言語などで効率的に実行する仕組み）の方が、Pythonの明示的な`for`ループよりもはるかに高速に動作することが多いです [15]。このため、Pythonのループを理解することは重要ですが、データサイエンスライブラリを学ぶ際には、これらの効率的な代替手段を意識することが求められます。", exerciseHint: "1から10までの数値を順番に表示する`for`ループを作成する。`while`ループを使って、ユーザーが特定の文字（例: 'q'）を入力するまで入力を求め続けるプログラムを作成する。リスト内の数値の合計を`for`ループを使って計算する。" },
                { title: "Unit 2.8: 関数の定義と呼び出し", goal: "独自の関数を定義し、呼び出す方法を習得する。引数と戻り値の概念を理解する。", topics: ["関数の必要性：処理のまとまりの作成、コードの再利用性の向上、可読性の向上。", "`def`キーワードによる関数の定義：`def function_name(parameter1, parameter2):`。", "引数（パラメータ）：関数に渡すデータ。", "戻り値 (`return`文）：関数が処理結果として返す値。何も返さない場合は `None` が返る。", "ローカル変数とグローバル変数のスコープの基本的な考え方。", "デフォルト引数値 (例: `def greet(name, message=\"Hello\"):`)。"], explanation: "関数は、特定のタスクを実行するための一連の処理をまとめたものです [8, 13]。関数を定義することで、同じ処理を何度も書く必要がなくなり、コードの再利用性が高まります。また、複雑な処理を小さな関数に分割することで、プログラム全体の見通しが良くなり、デバッグも容易になります [12]。データ分析のワークフローでは、特定のデータクリーニング手順や計算処理、可視化のパターンなどを関数として定義しておくと非常に便利です。これにより、分析スクリプトが整理され、他のプロジェクトでも同じ処理を簡単に再利用できるようになります。これは、優れたソフトウェアエンジニアリングの実践をデータサイエンスに応用する一例と言えます。", exerciseHint: "2つの数値を受け取り、その合計を返す関数 `add_numbers(a, b)` を作成する。半径を引数として受け取り、円の面積を計算して返す関数 `calculate_circle_area(radius)` を作成する（円周率は3.14159とする）。" },
                { title: "Unit 2.9: モジュールとimport文", goal: "モジュールの概念を理解し、`import`文を使ってモジュール内の関数や変数を利用する方法を習得する。", topics: ["モジュールとは：Pythonの定義や文（関数、クラス、変数など）が含まれたファイル (`.py`ファイル)。", "`import module_name`：モジュール全体をインポート。利用時は `module_name.object_name`。", "`from module_name import specific_object`：モジュールから特定のオブジェクト（関数、クラスなど）を直接インポート。利用時は `specific_object`。", "`from module_name import *`：モジュール内の全オブジェクトをインポート（非推奨、名前空間の衝突リスク）。", "`import module_name as alias`：エイリアス（別名）を付けてインポート (例: `import numpy as np`, `import pandas as pd`) [15]。", "標準ライブラリの簡単な紹介 (例: `math`モジュールで数学関数、`random`モジュールで乱数生成)。"], explanation: "モジュールは、関連する関数やクラスなどをまとめたもので、Pythonのコードを整理し、再利用可能にするための仕組みです [13]。Pythonには多くの標準ライブラリ（`math`、`datetime`、`random`など）が付属しており、これらを`import`文で読み込むことで、様々な機能を手軽に利用できます。さらに、データサイエンス分野では、NumPy、pandas、Matplotlib、scikit-learn、PyTorchといったサードパーティ製の強力なライブラリが広く使われており、これらも同様に`import`文を通じて利用します [15]。`import`文は、Pythonの広大なエコシステムへの入り口であり、これによってデータサイエンスに必要な専門的な機能へアクセスすることが可能になります。", exerciseHint: "`math`モジュールをインポートし、平方根を計算する関数 (`math.sqrt()`) と円周率の定数 (`math.pi`) を使って、半径5の円の面積を計算する。`random`モジュールをインポートし、1から6までのランダムな整数を生成する (`random.randint(1, 6)`)。" },
                { title: "Unit 2.10: (補足) Python環境について (Anacondaとpip)", goal: "Pythonのライブラリ管理の基本的な考え方（Anaconda Navigator, condaコマンド, pipコマンド）と仮想環境の重要性を理解する。", topics: ["ライブラリ（パッケージ）とは：特定の機能を提供するモジュールの集まり。", "Anaconda Navigatorの概要：GUIを通じた環境管理とパッケージ管理 [1, 3]。", "`conda`コマンドの基本 (Anaconda Promptまたはターミナルで実行)：\n    - パッケージのインストール：`conda install package_name`。\n    - インストール済みパッケージのリスト表示：`conda list`。", "`pip`コマンドの基本 (コマンドプロンプトまたはターミナルで実行)：\n    - パッケージのインストール：`pip install package_name` [3]。\n    - インストール済みパッケージのリスト表示：`pip list`。", "仮想環境の簡単な紹介とその重要性：プロジェクトごとに独立したライブラリ環境を作成 [5, 9]。"], explanation: "Pythonでデータサイエンスを行うには、様々なライブラリをインストールし管理する必要があります。Anacondaは、Python本体に加え、データサイエンスでよく使われる多数のライブラリをまとめて提供するディストリビューションであり、環境構築の手間を大幅に削減します [1, 3]。Anacondaには`conda`というパッケージ管理システムが含まれており、ライブラリのインストールやアップデート、仮想環境の作成が可能です。`pip`はPython公式のパッケージインストーラで、`conda`で提供されていないライブラリをインストールする際に使われます [3]。特に重要なのが「仮想環境」の概念です [5, 9]。プロジェクトごとに異なるライブラリのバージョンが必要になることがあるため、仮想環境を作成してプロジェクトごとに依存関係を分離することで、ライブラリ間のコンフリクトを防ぎ、プロジェクトの再現性を高めることができます。これは、共同作業や長期的なプロジェクト管理において非常に重要です。", exerciseHint: "Anaconda Prompt (またはターミナル) を開き、`conda list` や `pip list` を実行してインストール済みのライブラリを確認する。もし余裕があれば、簡単な名前で新しい仮想環境を作成し (`conda create -n myenv python=3.9`など)、その環境をアクティベート (`conda activate myenv`)、ディアクティベート (`conda deactivate`) してみる。" },
                { title: "Unit 2.11: 簡単なファイル入出力", goal: "テキストファイルの基本的な読み書き操作をPythonで行えるようになる。", topics: ["`open()`関数によるファイルのオープン：\n    - モード指定：`'r'` (読み込み専用、デフォルト)、`'w'` (書き込み専用、ファイルが存在すれば上書き)、`'a'` (追記、ファイルが存在すれば末尾に追加)。", "`with`文を使った安全なファイル操作：ブロック終了時に自動的にファイルをクローズする。\n    - 例: `with open('myfile.txt', 'r') as f:`", "ファイルの読み込みメソッド：\n    - `read()`: ファイル全体を一つの文字列として読み込む。\n    - `readline()`: ファイルから1行ずつ読み込む。\n    - `readlines()`: ファイル全体を1行ごとの文字列のリストとして読み込む。", "ファイルへの書き込みメソッド：`write()`。"], explanation: "データ分析では、外部ファイルからデータを読み込んだり、分析結果をファイルに出力したりする場面が頻繁にあります。Pythonの組み込み関数`open()`を使うことで、テキストファイルの基本的な読み書きが可能です [8, 10]。ファイルを扱う際には、`with`文を使用することが推奨されます。これにより、ファイル操作が終了した後（またはエラーが発生した場合でも）、ファイルが自動的に正しくクローズされるため、リソースリークを防ぐことができます。pandasのようなライブラリはCSVやExcelといった構造化データを扱うための高度な機能を提供しますが、基本的なテキストファイルの操作を理解しておくことは、非構造化データを扱ったり、簡単なログを出力したりする際に役立ちます。", exerciseHint: "Jupyter Notebookと同じディレクトリに、数行のテキストを含む `sample.txt` という名前のファイルを手動で作成する。Pythonでこのファイルを読み込み、内容を`print()`で表示する。次に、Pythonから `output.txt` という新しいファイルに自分の名前と今日の日付を書き込むプログラムを作成し、ファイルが正しく作成されているか確認する。" },
                { title: "Unit 2.12: エラーと例外処理の初歩 (try, except)", goal: "Pythonにおけるエラーの種類を理解し、`try-except`ブロックを使った基本的な例外処理を記述できるようになる。", topics: ["エラーの種類：\n    - 構文エラー (SyntaxError)：Pythonの文法に誤りがある場合に発生。プログラム実行前に検出される。\n    - 実行時エラー (例外, Exception)：プログラム実行中に発生するエラー。", "代表的な例外の例：`TypeError` (不適切な型のデータ操作)、`ValueError` (不適切な値)、`IndexError` (リスト等の範囲外アクセス)、`KeyError` (辞書の存在しないキーへのアクセス)、`FileNotFoundError` (存在しないファイルを開こうとした)。", "`try-except`文：エラーが発生する可能性のあるコードを`try`ブロックに記述し、エラーが発生した場合の処理を`except`ブロックに記述する。", "特定の例外の捕捉：`except ValueError:` のように、特定の例外タイプを指定して捕捉する。"], explanation: "プログラムを書いていると、様々なエラーに遭遇します。Pythonでは、文法的な誤りである「構文エラー」と、実行中に発生する「例外」があります [13]。例外が発生するとプログラムは通常そこで停止してしまいますが、`try-except`文を用いることで、例外を「捕捉」し、プログラムがクラッシュするのを防いだり、エラーに応じた適切な処理を行ったりすることができます。例えば、ユーザーからの入力が期待した形式でない場合や、処理しようとしたファイルが存在しない場合などに、エラーメッセージを表示して処理を継続する、あるいは代替処理を行うといった対応が可能になります。実世界のデータはしばしば不完全であったり予期せぬ形式であったりするため、堅牢なデータ分析スクリプトを作成するには、このような例外処理の知識が不可欠です。これにより、スクリプトが予期せぬ問題で停止することなく、より安定して動作するようになります。", exerciseHint: "ユーザーに数値を入力させ、その数値で10を割るプログラムを作成する。ユーザーが0を入力した場合（`ZeroDivisionError`）や、数値以外の文字を入力した場合（`ValueError`）に、それぞれ適切なエラーメッセージを表示するように`try-except`ブロックで処理する。" }
            ]
        },
        {
            title: "第3章: pandas基礎",
            summary: "この章では、Pythonでデータ分析を行うための強力なライブラリであるpandasの基礎を学びます [16]。pandasは、構造化データを効率的に操作し分析するための高性能なデータ構造（特にDataFrameとSeries）を提供します [16, 17]。CSVファイルやExcelファイルなど、様々な形式のデータの読み込み、データのクリーニング、変換、集計、結合といった、データ分析に不可欠な操作をpandasを使って行う方法を習得します。pandasを使いこなすことは、データサイエンティストにとって基本的なスキルの一つです [18]。",
            units: [
                { title: "Unit 3.1: pandasとは？SeriesとDataFrameの概要", goal: "pandasライブラリの役割と、主要なデータ構造であるSeriesとDataFrameの基本的な概念を理解する。", topics: ["pandasの紹介：Pythonにおけるデータ操作と分析のための主要ライブラリ [16]。", "Series：1次元のラベル付き配列。NumPyの配列に似ているが、インデックスを持つ [5, 16, 17]。\n    - リストやNumPy配列からの作成。\n    - インデックスの役割。", "DataFrame：2次元のラベル付きデータ構造。行と列からなり、ExcelのスプレッドシートやSQLのテーブルに似ている [5, 16]。\n    - 辞書やNumPy配列、Seriesからの作成。\n    - 各列はSeriesオブジェクト [17]。", "`import pandas as pd` の慣習 [17]。"], explanation: "pandasは、\"panel data\"（パネルデータ）という計量経済学の用語に由来する名前を持つ、オープンソースのPythonライブラリです [16]。データ分析において中心的な役割を果たし、特に構造化されたデータを扱うのに非常に強力です。pandasの主要なデータ構造は、1次元のラベル付き配列である「Series」と、2次元のテーブル形式のデータ構造である「DataFrame」です [5, 16]。Seriesは単一の列や行を表し、DataFrameは複数のSeriesが集まって表を形成していると考えることができます。DataFrameは、異なる型の列を持つことができ、データのクリーニング、変換、分析、可視化など、データサイエンスのワークフローの多くの段階で活用されます。pandasをインポートする際には、慣習として `import pandas as pd` とエイリアス `pd` を使用します [17]。", exerciseHint: "Pythonのリストから簡単なSeriesを作成し表示する。Pythonの辞書（キーが列名、値がリストのデータ）から簡単なDataFrameを作成し表示する。" },
                { title: "Unit 3.2: データの読み込みと書き出し (CSV, Excel)", goal: "CSVファイルやExcelファイルからデータをDataFrameに読み込み、またDataFrameをこれらの形式で書き出す方法を習得する。", topics: ["CSVファイルの読み込み：`pd.read_csv('filename.csv')` [5, 19]。\n    - 主要な引数：`sep` (区切り文字), `header` (ヘッダー行の指定), `index_col` (インデックス列の指定)。", "Excelファイルの読み込み：`pd.read_excel('filename.xlsx')` [16]。\n    - 主要な引数：`sheet_name` (シート名または番号の指定)。", "DataFrameの書き出し：\n    - CSVファイルへ：`df.to_csv('output.csv', index=False)` [17]。\n    - Excelファイルへ：`df.to_excel('output.xlsx', sheet_name='Sheet1', index=False)`。"], explanation: "データ分析の最初のステップは、多くの場合、外部ファイルからデータを読み込むことです。pandasは、CSV (Comma Separated Values) ファイルやExcelスプレッドシートなど、様々なファイル形式からのデータ読み込みをサポートしています [16, 19]。`pd.read_csv()` 関数はCSVファイルをDataFrameに、`pd.read_excel()` 関数はExcelファイルをDataFrameに読み込みます。これらの関数には、読み込み方を細かく制御するための多くのオプション（例えば、区切り文字の指定、ヘッダー行の有無、特定の列をインデックスとして使用するなど）が用意されています。逆に、分析結果や処理済みのデータをファイルに保存する際には、`df.to_csv()` や `df.to_excel()` といったメソッドを使用します [17]。これらの機能を使いこなすことで、様々なデータソースとの連携がスムーズになります。", exerciseHint: "簡単な内容のCSVファイル（例：名前,年齢,都市 の3列で数行のデータ）を手動で作成し、`pd.read_csv()`で読み込んで表示する。読み込んだDataFrameを別の名前でCSVファイルとして書き出す。" },
                { title: "Unit 3.3: DataFrameの基本情報確認", goal: "DataFrameの形状、データ型、基本統計量など、基本的な情報を確認する方法を習得する。", topics: ["先頭・末尾の表示：`df.head(n)` (先頭n行), `df.tail(n)` (末尾n行) [17]。", "DataFrameの形状（次元）：`df.shape` (行数, 列数)。", "列のデータ型：`df.dtypes`。", "基本情報（インデックス、列、非null値の数、メモリ使用量など）：`df.info()` [17]。", "要約統計量（数値列の平均、標準偏差、最小値、最大値など）：`df.describe()`。", "列名の一覧：`df.columns`。", "インデックスの一覧：`df.index`。"], explanation: "データを読み込んだ後、まず行うべきことは、そのデータがどのようなものかを確認することです。pandasのDataFrameには、このための便利な属性やメソッドが多数用意されています。`df.head()` や `df.tail()` を使うと、データの最初や最後の数行を表示して、おおまかな内容や形式を把握できます [17]。`df.shape` はDataFrameの行数と列数をタプルで返します。`df.dtypes` は各列のデータ型（整数、浮動小数点数、オブジェクト＝文字列など）を示し、`df.info()` はさらに詳細な情報（欠損値の数やメモリ使用量など）を提供します [17]。数値データが含まれる列に対して `df.describe()` を実行すると、平均値、標準偏差、最小値、最大値、四分位数といった基本的な統計量が一括で計算され、データの分布の概要を素早く掴むのに役立ちます。これらの情報を確認することは、データ分析の方向性を定める上で非常に重要です。", exerciseHint: "前のユニットで読み込んだDataFrameに対し、`head()`, `shape`, `dtypes`, `info()`, `describe()` をそれぞれ実行し、どのような情報が得られるか確認する。" },
                { title: "Unit 3.4: 列の選択、追加、削除", goal: "DataFrameから特定の列を選択したり、新しい列を追加したり、既存の列を削除したりする方法を習得する。", topics: ["単一列の選択：`df['column_name']` (結果はSeries) または `df.column_name` (列名がPythonの命名規則に合致する場合のみ) [17]。", "複数列の選択：`df[['col1', 'col2', 'col3']]` (結果はDataFrame) [17]。", "新しい列の追加：`df['new_column'] = values` (valuesはリスト、Series、または単一の値)。\n    - 既存の列から計算して新しい列を作成する例。", "列の削除：`del df['column_name']` または `df.drop(columns=['column_name'])`。"], explanation: "DataFrameを操作する上で、特定の列に注目したり、分析に必要な新しい列を作成したり、不要な列を削除したりする作業は頻繁に発生します。pandasでは、列名を指定することで簡単に列を選択できます。単一の列を選択するとSeriesオブジェクトが返され、複数の列を選択するとDataFrameオブジェクトが返されます [17]。新しい列を追加するには、DataFrameに新しい列名を指定し、そこに値を代入します。この値は、リストや他のSeries、あるいは既存の列を用いた計算結果など、様々な形で与えることができます。不要になった列は `del` 文や `drop()` メソッドを使って削除できます。これらの操作は、データの前処理や特徴量エンジニアリングにおいて基本的なステップとなります。", exerciseHint: "3列（例：商品名, 単価, 販売数）を持つDataFrameを作成する。「売上」という新しい列を「単価」×「販売数」で計算して追加する。その後、「単価」列を削除してみる。" },
                { title: "Unit 3.5: 行の選択 (loc, iloc)", goal: "DataFrameから特定の行をラベルや位置に基づいて選択する方法 (`loc`, `iloc`) を習得する。", topics: ["`loc`：ラベルベースの選択。行ラベル（インデックス名）と列ラベル（列名）で指定 [17]。\n    - 単一行の選択：`df.loc['row_label']`。\n    - 複数行の選択：`df.loc[['label1', 'label2']]`。\n    - 行と列の同時選択：`df.loc['row_label', 'col_label']` または `df.loc[['row1'], ['col1', 'col2']]`。\n    - スライシング：`df.loc['start_label':'end_label']` (end_labelも含む)。", "`iloc`：整数位置ベースの選択。行番号と列番号（0から始まる）で指定 [17]。\n    - 単一行の選択：`df.iloc[row_position]`。\n    - 複数行の選択：`df.iloc[[pos1, pos2]]`。\n    - 行と列の同時選択：`df.iloc[row_pos, col_pos]` または `df.iloc[[row1_pos], [col1_pos, col2_pos]]`。\n    - スライシング：`df.iloc[start_pos:end_pos]` (end_posは含まない、Python標準スライスと同じ)。"], explanation: "DataFrameから特定の行や、行と列の組み合わせでデータを抽出するには、`loc` と `iloc` という2つの主要なアクセサを使用します [17]。`loc` は、DataFrameのインデックス名（ラベル）と列名（ラベル）に基づいてデータを選択します。一方、`iloc` は、0から始まる行の位置番号と列の位置番号に基づいてデータを選択します。これらは、単一の要素、行全体、列全体、あるいは特定の範囲の行や列（スライシング）を選択するのに使えます。例えば、特定のIDを持つ顧客のデータ行を抽出したり、最初の10行の特定の数個の列だけを取り出したりする場合に便利です。`loc` と `iloc` の違いを正確に理解し、状況に応じて使い分けることが重要です。", exerciseHint: "5行3列程度のDataFrameを作成する。`loc`を使って特定のインデックス名の行を選択する。`iloc`を使って2番目の行を選択する。`loc`と`iloc`それぞれを使って、特定の行の特定の列の値をピンポイントで選択してみる。" },
                { title: "Unit 3.6: 条件による行の選択 (ブールインデックス)", goal: "条件式を使って、条件に合致する行をDataFrameから選択する方法（ブールインデックス）を習得する。", topics: ["条件式の作成：比較演算子 (`>`, `<`, `==`, `!=`など) を使ってSeriesに対して条件を適用すると、ブール値のSeriesが返る。\n    - 例：`df['age'] > 30`。", "ブール値のSeriesを `df[]` や `df.loc[]` に渡して行を選択。\n    - 例：`df[df['age'] > 30]`。", "複数の条件の組み合わせ：論理演算子 (`&` for AND, `|` for OR, `~` for NOT) を使用。括弧 `()` で条件の優先順位を明確にする。\n    - 例：`df[(df['age'] > 30) & (df['city'] == 'Tokyo')]`。", "`isin()` メソッド：複数の特定の値のいずれかに一致する行を選択。"], explanation: "データ分析では、「特定の条件を満たすデータだけを抽出したい」という場面が非常に多くあります。pandasでは、このような要求に「ブールインデックス」という強力な機能で応えます。まず、DataFrameの列に対して比較演算子などを用いて条件式を適用すると、各行がその条件を満たすかどうかを示すブール値（`True`または`False`）のSeriesが生成されます。このブール値のSeriesをDataFrameの `[]` や `df.loc[]` に渡すと、`True` に対応する行だけが抽出された新しいDataFrameが得られます。複数の条件を組み合わせる場合は、`&`（AND）、`|`（OR）、`~`（NOT）といった論理演算子を使用します。この際、各条件式を括弧で囲むことが重要です。ブールインデックスは、データクリーニングや探索的データ分析において非常に柔軟かつ強力なデータ抽出手段となります。", exerciseHint: "「名前」「年齢」「都市」の列を持つDataFrameを作成する。「年齢が30歳以上の人」の行を選択する。「都市が'Tokyo'で、かつ年齢が25歳未満の人」の行を選択する。" },
                { title: "Unit 3.7: 欠損値の取り扱い", goal: "DataFrame内の欠損値 (NaN) を検出し、処理する基本的な方法（削除、補完）を習得する。", topics: ["欠損値 (NaN - Not a Number) の概念。", "欠損値の検出：\n    - `df.isnull()` または `df.isna()`：要素ごとに欠損値かどうかを判定 (ブール値のDataFrame)。\n    - `df.isnull().sum()`：列ごとの欠損値の数を集計。", "欠損値の処理：\n    - 欠損値を含む行または列の削除：`df.dropna(axis=0)` (行), `df.dropna(axis=1)` (列)。\n        - `how='any'` (一つでもNaNがあれば削除), `how='all'` (全てNaNなら削除)。\n        - `thresh` (非NaN値の最小個数)。\n    - 欠損値の補完 (穴埋め)：`df.fillna(value)`。\n        - 特定の値で補完 (例: 0、平均値、中央値)。\n        - `method='ffill'` (前の値で補完), `method='bfill'` (後の値で補完)。"], explanation: "実際のデータセットには、値が記録されていない「欠損値」が含まれていることがよくあります。pandasでは、欠損値は通常 `NaN` (Not a Number) として表現されます。欠損値はそのままでは分析や機械学習モデルの学習に問題を引き起こすことがあるため、適切に処理する必要があります [19]。まず、`isnull()` や `isna()` メソッドを使ってデータ内のどこにどれだけ欠損値が存在するかを確認します。その上で、欠損値を含む行や列を削除する (`dropna()`)か、あるいは何らかの値で補完する (`fillna()`) といった対応を取ります。補完する値としては、0、平均値、中央値、最頻値などが考えられますし、時系列データであれば前後の値で補完することもあります。どの処理方法を選択するかは、データの特性や分析の目的に応じて慎重に判断する必要があります。", exerciseHint: "意図的に欠損値 (`np.nan` を使用 – NumPyの詳細は次章) を含むDataFrameを作成する。`isnull().sum()`で欠損値の数を確認する。`dropna()`で欠損値を含む行を削除してみる。`fillna()`で欠損値を0や列の平均値で補完してみる。" },
                { title: "Unit 3.8: 簡単な集計とグループ化 (groupby)", goal: "DataFrameの基本的な集計操作（合計、平均など）と、`groupby()`を使ったグループごとの集計方法を習得する。", topics: ["基本的な集計関数：`sum()`, `mean()`, `median()`, `min()`, `max()`, `count()`, `std()` (標準偏差), `var()` (分散)。\n    - DataFrame全体、または列ごと (`axis=0`)、行ごと (`axis=1`) に適用可能。", "`groupby()`によるグループ化：特定の列の値を基準にデータをグループに分割 [5, 18, 19]。\n    - `df.groupby('column_name')` でGroupByオブジェクトを生成。\n    - GroupByオブジェクトに対して集計関数を適用 (例: `df.groupby('category')['sales'].sum()`)。", "複数の列によるグループ化：`df.groupby(['col1', 'col2'])`。", "`agg()`メソッドを使った複数の集計処理。"], explanation: "データ分析では、全体の傾向を把握したり、特定のカテゴリごとの特徴を比較したりするために、データの集計が不可欠です。pandasでは、`sum()`（合計）、`mean()`（平均）、`count()`（個数）といった多くの集計関数が用意されており、DataFrameやSeriesに直接適用できます [20]。さらに強力なのが `groupby()` メソッドです [5, 19]。これは、指定した列の値をキーとしてデータをグループに分割し、各グループに対して独立して集計処理を行うことを可能にします。例えば、「商品カテゴリごとの売上合計」や「部署ごとの平均年齢」などを簡単に計算できます。`groupby()` は、データをより深く理解するための強力なツールであり、SQLのGROUP BY句と同様の機能を提供します。", exerciseHint: "「商品カテゴリ」「商品名」「売上」の列を持つDataFrameを作成する。全体の総売上と平均売上を計算する。「商品カテゴリ」ごとの総売上と平均売上を`groupby()`を使って計算する。" },
                { title: "Unit 3.9: DataFrameの結合と連結 (merge, concat)", goal: "複数のDataFrameを結合 (merge) および連結 (concat) する基本的な方法を習得する。", topics: ["連結 (`pd.concat([df1, df2])`)：DataFrameを縦方向 (行を追加、`axis=0`) または横方向 (列を追加、`axis=1`) に単純に繋げる。\n    - インデックスの扱い (`ignore_index=True`)。", "結合 (`pd.merge(df_left, df_right, on='key_column', how='inner')`)：SQLのJOINのように、共通のキー列を基準にDataFrameを結合する [16, 19]。\n    - `on`: 結合キーとなる列名。左右でキー列名が異なる場合は `left_on`, `right_on`。\n    - `how`: 結合方法の指定。\n        - `'inner'` (内部結合): 両方のDataFrameにキーが存在する行のみ。\n        - `'left'` (左外部結合): 左DataFrameの全行を残し、右DataFrameにキーがなければNaN。\n        - `'right'` (右外部結合): 右DataFrameの全行を残し、左DataFrameにキーがなければNaN。\n        - `'outer'` (完全外部結合): 両方のDataFrameの全行を残し、対応するキーがなければNaN。"], explanation: "実際のデータ分析プロジェクトでは、データが複数のファイルやテーブルに分割されていることがよくあります。このような場合、それらのデータを一つにまとめる作業が必要になります。pandasでは、`pd.concat()` と `pd.merge()` という2つの主要な関数でこれに対応します [16, 19]。`pd.concat()` は、複数のDataFrameを単純に縦方向または横方向に連結します。一方、`pd.merge()` は、データベースのJOIN操作のように、一つ以上の共通のキー列を基準にして、異なるDataFrameの行を関連付けて結合します。結合方法には、内部結合、左外部結合、右外部結合、完全外部結合などがあり、分析の目的に応じて適切な方法を選択する必要があります。これらの機能を理解することで、複数のデータソースを統合してより包括的な分析を行うことが可能になります。", exerciseHint: "顧客情報（顧客ID, 氏名）を持つDataFrameと、購買履歴（顧客ID, 商品名, 金額）を持つDataFrameをそれぞれ作成する。`pd.merge()`を使って、顧客IDをキーとしてこれら2つのDataFrameを内部結合および左外部結合してみる。" }
            ]
        },
        {
            title: "第4章: NumPy基礎",
            summary: "この章では、Pythonにおける数値計算の基本的なパッケージであるNumPy (Numerical Python) の基礎を学びます [15, 21]。NumPyは、高性能な多次元配列オブジェクト (ndarray) と、これらの配列を操作するための豊富な関数群を提供します [15]。ベクトルや行列といった数学的なオブジェクトを効率的に扱うことができ、科学技術計算やデータ分析、機械学習の分野で広く利用されています [5, 22]。pandasやscikit-learnなど、多くのデータサイエンスライブラリが内部的にNumPyを利用しており、NumPyの理解はこれらのライブラリを効果的に使うための基盤となります。",
            units: [
                { title: "Unit 4.1: NumPyとは？ndarrayの概要", goal: "NumPyライブラリの役割と、中心的なデータ構造であるndarrayの基本的な特性を理解する。", topics: ["NumPyの紹介：Pythonでの高速な数値計算、特に配列操作のためのライブラリ [15]。", "ndarray (N-dimensional array)：NumPyの基本的なデータ構造。同じ型の要素からなる多次元配列 [14, 15]。\n    - Pythonのリストとの違い：固定型、より効率的なメモリ使用と演算速度 [15]。", "ndarrayの属性：\n    - `ndim`：次元数 (ランク) [14]。\n    - `shape`：各次元のサイズ (形状) [14, 23]。\n    - `size`：全要素数。\n    - `dtype`：要素のデータ型 (例: `int64`, `float64`) [15]。", "`import numpy as np` の慣習 [14, 15]。"], explanation: "NumPyは、Pythonで科学計算を行うための基盤となるライブラリです [15]。その中核となるのが `ndarray` と呼ばれる多次元配列オブジェクトで、ベクトル（1次元配列）、行列（2次元配列）、さらに高次元のテンソルを表現できます。Python標準のリストとは異なり、`ndarray` の要素はすべて同じデータ型でなければならず、これによりメモリ効率が高く、数値演算も高速に行えます [15]。これは、NumPyの多くの演算がコンパイルされたC言語のコードで実装されているためです。`ndarray` は、その次元数 (`ndim`)、各次元の大きさ (`shape`)、要素のデータ型 (`dtype`) といった重要な属性を持ちます [14]。データサイエンスや機械学習の多くの場面で、データはNumPy配列の形で扱われるため、その特性を理解することは非常に重要です。", exerciseHint: "`import numpy as np` を実行する。Pythonのリスト `[1, 2, 3]` からNumPy配列を作成し、その `ndim`, `shape`, `dtype` を表示する。" },
                { title: "Unit 4.2: NumPy配列の作成", goal: "様々な方法でNumPy配列を作成できるようになる。", topics: ["Pythonのリストやタプルから作成：`np.array([1, 2, 3])`, `np.array([[1, 2], [3, 4]])` [14]。", "特定の値で埋められた配列の作成：\n    - `np.zeros(shape)`：全て0の配列 [22]。\n    - `np.ones(shape)`：全て1の配列。\n    - `np.full(shape, fill_value)`：指定した値で埋められた配列。\n    - `np.empty(shape)`：初期化されていない配列（高速だが内容は不定）。", "連番配列の作成：\n    - `np.arange(start, stop, step)`：指定範囲・間隔の整数列 (stopは含まない) [23]。\n    - `np.linspace(start, stop, num)`：指定範囲を等間隔にnum個の点で分割した数列 (stopも含む) [22]。", "単位行列の作成：`np.eye(N)`。", "乱数による配列の作成 (`np.random` モジュール)：\n    - `np.random.rand(d0, d1,...)`：0から1までの一様乱数。\n    - `np.random.randn(d0, d1,...)`：標準正規分布に従う乱数。\n    - `np.random.randint(low, high, size)`：指定範囲の整数乱数。"], explanation: "NumPy配列は様々な方法で作成できます。最も基本的なのは、Pythonのリストやネストされたリスト（多次元の場合）を `np.array()` 関数に渡す方法です [14]。また、特定の値（例えば全て0や全て1）で初期化された配列や、連続した数値（`np.arange()` や `np.linspace()` を使用）、あるいは乱数で満たされた配列を生成する便利な関数も多数提供されています [22, 23]。これらの関数を使いこなすことで、分析やシミュレーションに必要な様々な種類のデータを効率的に準備することができます。特に、機械学習モデルの重みの初期化や、テストデータの生成などで乱数配列は頻繁に利用されます。", exerciseHint: "`(3, 3)` の形状で全て0の配列、全て1の配列を作成する。0から9までの整数が並ぶ1次元配列を `np.arange()` で作成する。0から1までの値を5等分する配列を `np.linspace()` で作成する。`np.random.rand(2, 3)` で乱数配列を作成する。" },
                { title: "Unit 4.3: 配列のインデックス参照とスライシング", goal: "NumPy配列の要素や部分配列にアクセスするためのインデックス参照とスライシング操作を習得する。", topics: ["1次元配列：Pythonのリストと同様。\n    - インデックス参照：`arr[i]` [14]。\n    - スライシング：`arr[start:stop:step]`。", "多次元配列：各次元に対してインデックスやスライスを指定。\n    - インデックス参照：`arr[row, col]` または `arr[row][col]`。\n    - スライシング：`arr[row_slice, col_slice]` (例: `arr[1:3, 0:2]`) [12]。\n    - 特定の行/列の取得：`arr[i, :]` (i行目全体), `arr[:, j]` (j列目全体)。", "スライスは元の配列のビュー（浅いコピー）であることに注意 [14]。ビューへの変更は元の配列にも影響する。コピーを作成するには `.copy()` メソッドを使用。"], explanation: "NumPy配列の個々の要素や一部分（部分配列）にアクセスするためには、インデックス参照とスライシングを用います。1次元配列の場合、操作方法はPythonのリストとほぼ同じです [14]。多次元配列では、各次元に対してカンマ区切りでインデックスやスライスを指定します [12]。例えば、2次元配列 `arr` の `i` 行 `j` 列の要素は `arr[i, j]` でアクセスできます。スライシングを使うと、配列の特定の行、列、あるいは矩形領域を効率的に抽出できます。重要な点として、NumPyのスライシングで得られる部分配列は、多くの場合、元の配列のデータ領域を共有する「ビュー」となります [14]。これはメモリ効率を高めるための仕様ですが、ビューを通じて値を変更すると元の配列の値も変わってしまうため、意図しない副作用に注意が必要です。独立したコピーが必要な場合は、`.copy()` メソッドを明示的に呼び出す必要があります。", exerciseHint: "`np.arange(1, 10).reshape(3, 3)` で3x3の配列を作成する。2行1列目の要素（値は4のはず）を表示する。1行目全体（`arr[0, :]`）を表示する。中央の2x2の部分配列（`arr[1:3, 1:3]`）をスライシングで取り出す。" },
                { title: "Unit 4.4: ブールインデックスとファンシーインデックス", goal: "条件に基づく要素選択（ブールインデックス）と、インデックスの配列を使った要素選択（ファンシーインデックス）を習得する。", topics: ["ブールインデックス (Boolean Indexing)：\n    - 配列に対して条件式を適用すると、ブール値の配列が返る (例: `arr > 5`) [12]。\n    - このブール配列を使って、条件に合致する要素だけを抽出 (例: `arr[arr > 5]`)。\n    - 複数の条件の組み合わせ (`&`, `|`)。", "ファンシーインデックス (Fancy Indexing)：\n    - インデックスの配列（リストやNumPy配列）を使って、特定の順序で要素を選択・抽出 [12]。\n    - 例：`arr[[1, 0, 2]]` (1番目、0番目、2番目の順で行を選択)。\n    - 多次元配列の場合、行と列それぞれにインデックス配列を指定可能。", "ブールインデックスやファンシーインデックスで抽出した結果は、元の配列のコピーとなる（ビューではない）。"], explanation: "NumPyでは、より柔軟な要素選択方法として、ブールインデックスとファンシーインデックスが提供されています。ブールインデックスは、配列の各要素に対して条件を評価し、その結果（`True`または`False`）に基づいて要素を選択する手法です [12]。例えば、「配列内の5より大きい要素だけを取り出す」といった操作が可能です。これはデータフィルタリングに非常に便利です。ファンシーインデックスは、整数配列（またはリスト）をインデックスとして使用し、配列から特定の順序や組み合わせで要素を抽出します [12]。例えば、特定の行を任意の順序で取り出したり、特定の座標の要素を複数同時に取得したりできます。これらの高度なインデックス機能は、複雑なデータ操作を簡潔に記述するのに役立ちます。", exerciseHint: "`np.array([1, 8, 3, 6, 2, 7, 4, 9, 5])` という配列を作成する。この配列から5より大きい要素だけをブールインデックスで抽出する。インデックス `[2, 0, 3]` に対応する要素をファンシーインデックスで抽出する。" },
                { title: "Unit 4.5: 配列の演算 (要素ごと、ブロードキャスト)", goal: "NumPy配列間の要素ごとの演算と、形状が異なる配列間で演算を可能にするブロードキャストの概念を理解する。", topics: ["要素ごとの演算 (Element-wise operations)：同じ形状の配列間では、対応する要素同士で算術演算 (`+`, `-`, `*`, `/`, `**`など) が行われる。\n    - 配列とスカラ値の演算も可能（スカラ値が配列の全要素に適用される）。", "ブロードキャスト (Broadcasting)：形状が異なる配列間でも、特定のルールに従って自動的に形状を拡張し、要素ごとの演算を可能にする仕組み [15]。\n    - ブロードキャストのルール：次元数が少ない方を後方から合わせ、各次元のサイズが一致するか、一方が1であれば互換性あり。サイズ1の次元は他方のサイズに合わせて拡張される。\n    - 例：(3,3)形状の配列と(3,)形状の配列（または(1,3)や(3,1)）の演算。"], explanation: "NumPy配列の大きな利点の一つは、ループを使わずに配列全体に対して高速な演算を行えることです。同じ形状の配列同士であれば、算術演算子は要素ごとに適用されます（例えば、`arr1 + arr2` は対応する要素同士の和からなる新しい配列を返します）。配列とスカラ値（単一の数値）の間の演算も同様に、スカラ値が配列の全要素に対して作用します。さらに強力なのが「ブロードキャスト」という機能です [15]。これは、形状が完全に一致しない配列間でも、NumPyが一定のルールに従って一方または両方の配列の形状を仮想的に拡張し、要素ごとの演算を実行できるようにする仕組みです。例えば、2次元配列の各行に同じ1次元配列（ベクトル）を加算するような操作が、明示的なループなしに簡潔に記述できます。ブロードキャストを理解することは、NumPyを効率的に使いこなす上で非常に重要です。", exerciseHint: "2つの同じ形状のNumPy配列を作成し、加算、乗算を行う。NumPy配列とスカラ値の演算（例：配列の全要素を2倍する）を行う。形状が `(3,3)` の配列と形状が `(3,)` の配列（例：`np.array([1, 0, 1])`）を作成し、これらを加算してみる（ブロードキャストがどのように働くか観察する）。" },
                { title: "Unit 4.6: 基本的な数学関数と統計関数", goal: "NumPyが提供する主要な数学関数（ユニバーサル関数, ufunc）と統計関数を扱えるようになる。", topics: ["ユニバーサル関数 (ufunc)：配列の各要素に対して高速に作用する関数。\n    - 数学関数：`np.sqrt()`, `np.exp()`, `np.log()`, `np.sin()`, `np.cos()` など。", "集計関数（統計関数）：\n    - 合計：`np.sum(arr)` または `arr.sum()`。\n    - 平均：`np.mean(arr)` または `arr.mean()`。\n    - 標準偏差：`np.std(arr)` または `arr.std()`。\n    - 分散：`np.var(arr)` または `arr.var()`。\n    - 最小値：`np.min(arr)` または `arr.min()`。\n    - 最大値：`np.max(arr)` または `arr.max()`。\n    - 最小値/最大値のインデックス：`np.argmin(arr)` / `arr.argmin()`, `np.argmax(arr)` / `arr.argmax()`。", "`axis`引数による操作軸の指定：多次元配列の場合、行ごとや列ごとの集計が可能。\n    - `axis=0` (列方向の操作、結果は行ベクトル的に), `axis=1` (行方向の操作、結果は列ベクトル的に)。"], explanation: "NumPyは、配列操作だけでなく、豊富な数学関数や統計関数も提供しています。`np.sqrt()`（平方根）、`np.exp()`（指数関数）、`np.sin()`（正弦）などの「ユニバーサル関数」（ufunc）は、配列の各要素に対して高速に演算を行います。また、`np.sum()`（合計）、`np.mean()`（平均）、`np.std()`（標準偏差）といった集計関数は、配列全体の統計値や、指定した軸（行方向または列方向）に沿った統計値を計算するのに役立ちます [14]。これらの関数は、データの特徴を把握したり、前処理を行ったりする際に頻繁に利用されます。例えば、データセットの各特徴量の平均値や標準偏差を計算することは、データのスケーリング（正規化や標準化）の準備として一般的です。", exerciseHint: "1から10までの整数を含む配列を作成し、その平方根、合計、平均、標準偏差を計算する。2次元配列を作成し、列ごとの合計と行ごとの平均を `axis` 引数を指定して計算する。" },
                { title: "Unit 4.7: 配列の形状操作と転置", goal: "NumPy配列の形状を変更する (`reshape`)、次元を追加/削除する、配列を転置する方法を習得する。", topics: ["形状の変更：`arr.reshape(new_shape)`。要素数を変えずに形状を変更。\n    - `new_shape` の一部に `-1` を指定すると、他の次元から自動計算される。", "平坦化 (1次元配列に変換)：`arr.flatten()` (コピーを返す), `arr.ravel()` (可能な場合はビューを返す)。", "次元の追加：`np.newaxis` または `np.expand_dims()` [14]。\n    - 例：`arr[:, np.newaxis]` (1次元配列を列ベクトルに変換)。", "次元の削除：`np.squeeze()` (サイズ1の次元を削除)。", "転置：`arr.T` または `arr.transpose()`。2次元配列の場合、行と列を入れ替える。"], explanation: "データ分析や機械学習では、アルゴリズムの入力要件に合わせて配列の形状を操作する必要がしばしば生じます。NumPyの `reshape()` メソッドは、配列の要素数を変えずにその形状を変更します。例えば、1次元の長い配列を2次元の行列に変換することができます。`flatten()` や `ravel()` は多次元配列を1次元に平坦化します。`np.newaxis` や `np.expand_dims()` を使うと、配列に新しい次元を追加できます [14]。これは、例えば1次元配列を機械学習ライブラリが期待する列ベクトルや行ベクトルの形式に変換する際に便利です。`arr.T` や `arr.transpose()` は配列を転置し、2次元配列の場合は行と列が入れ替わります。これらの形状操作を理解することで、様々なデータ形式やライブラリの要求に柔軟に対応できるようになります。", exerciseHint: "`np.arange(12)` で配列を作成する。これを `(3, 4)`、`(4, 3)`、`(2, 6)` の形状にそれぞれ `reshape` してみる。作成した `(3, 4)` の配列を転置 (`.T`) して形状を確認する。1次元配列 `np.array([1,2,3])` を `np.newaxis` を使って列ベクトル（形状 `(3,1)`）に変換する。" },
                { title: "Unit 4.8: 配列の結合と分割", goal: "複数のNumPy配列を結合したり、一つの配列を複数の小さな配列に分割したりする方法を習得する。", topics: ["配列の結合：\n    - `np.concatenate((arr1, arr2,...), axis=0)`：指定した軸に沿って配列を連結。\n    - `np.vstack((arr1, arr2))`：垂直方向（行方向）にスタック (縦積み)。`concatenate` の `axis=0` と類似。\n    - `np.hstack((arr1, arr2))`：水平方向（列方向）にスタック (横積み)。`concatenate` の `axis=1` と類似 (2次元以上の場合)。", "配列の分割：\n    - `np.split(arr, N_or_indices, axis=0)`：指定した軸に沿って配列をN個に等分割、または指定したインデックスで分割。\n    - `np.hsplit(arr, N_or_indices)`：水平方向（列方向）に分割。\n    - `np.vsplit(arr, N_or_indices)`：垂直方向（行方向）に分割。"], explanation: "複数のデータソースから得られたNumPy配列を一つにまとめたり、逆に大きな配列を処理しやすい単位に分割したりする必要がある場合があります。`np.concatenate()` 関数は、複数の配列を指定した軸（次元）に沿って連結します。`np.vstack()` は配列を垂直方向に（行を追加するように）、`np.hstack()` は水平方向に（列を追加するように）積み重ねます。これらは、特徴量セットを結合したり、異なるバッチのデータをまとめたりする際に便利です。一方、`np.split()` 関数とそのヘルパー関数である `np.hsplit()`（水平分割）および `np.vsplit()`（垂直分割）は、一つの配列を複数の小さな配列に分割します。これは、データセットを訓練用とテスト用に分割したり、クロスバリデーションのためにデータを分割したりする際に利用できます。", exerciseHint: "2つの2x2のNumPy配列を作成する。これらを `np.concatenate` (axis=0 と axis=1)、`np.vstack`、`np.hstack` でそれぞれ結合し、結果の形状を確認する。4x4の配列を作成し、`np.split` で2つの2x4配列に、また `np.hsplit` で2つの4x2配列に分割してみる。" }
            ]
        },
        {
            title: "第5章: Matplotlib基礎",
            summary: "この章では、Pythonで静的、アニメーション、対話的な視覚化を作成するための包括的なライブラリであるMatplotlibの基礎を学びます [24, 25]。データ分析の結果を他者に伝えたり、データに潜むパターンや傾向を自身で理解したりするためには、データの視覚化が不可欠です [26]。Matplotlibは、折れ線グラフ、棒グラフ、散布図、ヒストグラムなど、様々な種類のグラフを柔軟に描画する機能を提供します。この章では、`matplotlib.pyplot`モジュールを中心に、基本的なグラフの作成方法とカスタマイズ方法を習得します。",
            units: [
                { title: "Unit 5.1: Matplotlibとは？pyplotの基本", goal: "Matplotlibライブラリの役割と、`matplotlib.pyplot`モジュールの基本的な使い方を理解する。", topics: ["Matplotlibの紹介：Pythonの代表的なデータ可視化ライブラリ [24, 25]。", "`matplotlib.pyplot`モジュール：MATLABライクなコマンドスタイルでグラフを描画するための関数の集まり [24, 25]。", "基本的な描画フロー：\n    1.  `import matplotlib.pyplot as plt` の慣習 [24]。\n    2.  データの準備 (PythonリストやNumPy配列)。\n    3.  `plt.plot()` などの描画関数でグラフを作成。\n    4.  `plt.show()` でグラフを表示。", "Jupyter Notebook内での表示 (`%matplotlib inline` マジックコマンドなど) [27]。"], explanation: "Matplotlibは、Pythonで高品質なグラフを生成するためのデファクトスタンダードなライブラリです [24, 25]。その中でも `matplotlib.pyplot` モジュールは、MATLABのプロット機能に似たインターフェースを提供し、比較的簡単に様々なグラフを作成することができます [24]。基本的なグラフ描画は、まず `matplotlib.pyplot` を `plt` というエイリアスでインポートし、描画したいデータを準備（通常はPythonのリストやNumPy配列）、`plt.plot()` などの関数でプロット内容を定義し、最後に `plt.show()` で実際にグラフを表示するという流れになります。Jupyter Notebook環境では、`%matplotlib inline` というマジックコマンドをセルの先頭で実行しておくことで、`plt.show()` を呼び出すとグラフがノートブックの出力セル内に直接埋め込まれて表示されるようになります [27]。", exerciseHint: "`import matplotlib.pyplot as plt` と `%matplotlib inline` (Jupyter Notebookの場合) を実行する。簡単なリスト `x = [1,2,3]`, `y = [2,4,1]` を作成し、`plt.plot(x, y)` と `plt.show()` で折れ線グラフを描画する。" },
                { title: "Unit 5.2: 折れ線グラフの作成とカスタマイズ", goal: "`plt.plot()` を使って折れ線グラフを作成し、線の色、スタイル、マーカーなどをカスタマイズできるようになる。", topics: ["`plt.plot(x, y)`：xデータとyデータに基づいて折れ線グラフを描画 [24]。\n    - xデータを省略した場合、yデータのインデックスがx軸として使われる [24]。", "線のスタイルの指定：\n    - 色 (例: `'r'` 赤, `'g'` 緑, `'b'` 青, `'k'` 黒) [24, 25]。\n    - 線種 (例: `'-'` 実線, `'--'` 破線, `':'` 点線, `'-.'` 一点鎖線) [24]。\n    - マーカー (例: `'.'` 点, `'o'` 円, `'^'` 三角, `'s'` 四角, `'x'` バツ) [24, 27]。\n    - 書式文字列 (例: `'ro-'` 赤い円マーカーの実線) [24, 25]。", "キーワード引数による詳細設定：`color`, `linestyle`, `linewidth`, `marker`, `markersize` など [24, 25]。", "複数の折れ線グラフを一つの図に描画：`plt.plot()` を複数回呼び出す [24]。"], explanation: "折れ線グラフは、時間経過に伴うデータの変化や、2つの連続変数の関係性を示すのによく使われます。Matplotlibでは `plt.plot()` 関数がこの役割を担います [24]。x軸のデータとy軸のデータをリストやNumPy配列として渡すことで基本的な折れ線グラフが描画できます。さらに、線の色、太さ、種類（実線、破線など）、データポイントを示すマーカーの種類やサイズなどを細かくカスタマイズすることが可能です [24, 25, 27]。これらのカスタマイズは、書式文字列（例: `'r--o'` は赤い破線に丸マーカー）や、`color='red'`, `linestyle='dashed'`, `marker='o'` のようなキーワード引数を使って行います。一つの図に複数の折れ線を重ねて描画することもでき、データの比較に役立ちます。", exerciseHint: "`x`軸を0から$2\\pi$までの範囲とし、NumPyを使って `sin(x)` と `cos(x)` のデータを生成する。これらを一つの図に、それぞれ異なる色と線種で折れ線グラフとして描画する。" },
                {
                    title: "Unit 5.3: 棒グラフ、散布図、ヒストグラムの作成",
                    goal: "棒グラフ (`plt.bar()`)、散布図 (`plt.scatter()`)、ヒストグラム (`plt.hist()`) を作成できるようになる。",
                    topics: [
                        "棒グラフ (`plt.bar(x, height)`)：カテゴリ間の量を比較 [26]。\n    - `x`: カテゴリの位置（通常は数値のシーケンス）、`height`: 各棒の高さ。\n    - `width`: 棒の幅、`color`: 棒の色。\n    - 横棒グラフ：`plt.barh()`。",
                        "散布図 (`plt.scatter(x, y)`)：2つの量的変数の関係性、相関の有無などを視覚化 [26]。\n    - `s`: マーカーのサイズ、`c`: マーカーの色、`marker`: マーカーの種類。",
                        "ヒストグラム (`plt.hist(data, bins=N)`)：量的データの分布形状（度数分布）を視覚化 [26]。\n    - `data`: 1次元のデータ配列。\n    - `bins`: ビン（階級）の数または境界値。\n    - `density`: Trueにすると正規化され面積が1になる（確率密度）。"
                    ],
                    explanation: "Matplotlibでは折れ線グラフ以外にも様々な種類の基本的なグラフを簡単に作成できます。棒グラフ (`plt.bar()`) は、カテゴリごとの数量を比較するのに適しており、例えば商品別の売上高やアンケートの回答項目別人数などを表現するのに使われます [26]。散布図 (`plt.scatter()`) は、2つの量的変数の間の関係性や分布のパターン、外れ値の存在などを視覚的に捉えるのに役立ちます [26]。各データポイントが点でプロットされ、点の密集具合や傾向から変数間の相関などを推測できます。ヒストグラム (`plt.hist()`) は、単一の量的データの分布を視覚化するもので、データがどの範囲にどれだけ集中しているか、分布が山形か、歪んでいるかなどを把握するのに用います [26]。これらのグラフを適切に使い分けることで、データの多面的な理解が深まります。",
                    exerciseHint: "いくつかのカテゴリ名とその値を持つデータから棒グラフを作成する。2つの相関がありそうな量的データ（例：身長と体重のダミーデータ）をNumPyの乱数で生成し、散布図で表示する。正規分布に従う乱数を1000個生成し、ヒストグラムでその分布を表示する。",
                    chartConfigs: [
                        {
                            id: 'barChartExample',
                            type: 'bar',
                            data: {
                                labels: ['カテゴリA', 'カテゴリB', 'カテゴリC', 'カテゴリD'],
                                datasets: [{
                                    label: 'サンプル値',
                                    data: [12, 19, 3, 5],
                                    backgroundColor: 'rgba(75, 192, 192, 0.6)',
                                    borderColor: 'rgba(75, 192, 192, 1)',
                                    borderWidth: 1
                                }]
                            },
                            options: {
                                responsive: true,
                                maintainAspectRatio: false,
                                scales: { y: { beginAtZero: true } },
                                plugins: { legend: { display: true } }
                            },
                            title: "棒グラフの例"
                        },
                        {
                            id: 'scatterPlotExample',
                            type: 'scatter',
                            data: {
                                datasets: [{
                                    label: 'サンプル散布図',
                                    data: Array.from({length: 50}, () => ({x: Math.random()*10, y: Math.random()*10 + Math.random()*5})),
                                    backgroundColor: 'rgba(255, 99, 132, 0.6)',
                                }]
                            },
                            options: {
                                responsive: true,
                                maintainAspectRatio: false,
                                scales: { x: { type: 'linear', position: 'bottom' }, y: { beginAtZero: true } },
                                plugins: { legend: { display: true } }
                            },
                            title: "散布図の例"
                        },
                        {
                            id: 'histogramExample',
                            type: 'bar',
                            data: {
                                labels: ['0-2', '2-4', '4-6', '6-8', '8-10'],
                                datasets: [{
                                    label: 'サンプルヒストグラム (正規分布風)',
                                    data: [50, 200, 300, 200, 50],
                                    backgroundColor: 'rgba(153, 102, 255, 0.6)',
                                    borderColor: 'rgba(153, 102, 255, 1)',
                                    borderWidth: 1
                                }]
                            },
                             options: {
                                responsive: true,
                                maintainAspectRatio: false,
                                scales: { y: { beginAtZero: true }, x: { categoryPercentage: 1.0, barPercentage: 1.0 } },
                                plugins: { legend: { display: true } }
                            },
                            title: "ヒストグラムの例"
                        }
                    ]
                },
                { title: "Unit 5.4: ラベル、タイトル、凡例の追加", goal: "グラフに軸ラベル、タイトル、凡例を追加し、より分かりやすいグラフを作成できるようになる。", topics: ["軸ラベルの設定：`plt.xlabel('X-axis Label')`, `plt.ylabel('Y-axis Label')` [24, 27]。", "タイトルの設定：`plt.title('Graph Title')` [24, 27]。", "凡例の追加：\n    - `plt.plot()` の `label` 引数で各プロットにラベルを付ける。\n    - `plt.legend()` で凡例を表示 [27]。\n    - 凡例の位置指定 (`loc`引数: `'upper right'`, `'best'`など) [27]。", "文字サイズや色の変更：`fontsize`, `color`などの引数を利用 [27]。"], explanation: "グラフを作成する際には、それが何を表しているのかを明確に伝えるために、適切なラベルやタイトルを付けることが非常に重要です。Matplotlibでは、`plt.xlabel()` と `plt.ylabel()` を使ってそれぞれX軸とY軸に説明ラベルを、`plt.title()` を使ってグラフ全体にタイトルを設定できます [24, 27]。一つの図に複数のデータ系列（例えば、複数の折れ線）を描画する場合には、それぞれが何を示しているのかを区別するために凡例が必要です。これには、まず `plt.plot()` などの描画関数の `label` 引数で各データ系列に名前を付け、その後 `plt.legend()` を呼び出すことで凡例が表示されます [27]。これらの要素を適切に設定することで、グラフの可読性が格段に向上し、データから得られる洞察を効果的に伝えることができます。", exerciseHint: "Unit 5.2で作成したsin(x)とcos(x)のグラフに、X軸ラベル「x」、Y軸ラベル「y」、タイトル「Sine and Cosine Curves」、そして各線に対応する凡例（「sin(x)」「cos(x)」）を追加する。" },
                { title: "Unit 5.5: 複数のグラフの描画 (サブプロット)", goal: "一つの図 (Figure) の中に複数のグラフ領域 (Axes/Subplot) を作成し、それぞれに異なるグラフを描画できるようになる。", topics: ["FigureとAxesの概念：Figureは図全体を指すキャンバス、Axesは個々のプロット領域 [24]。", "`plt.figure()`：新しいFigureを作成。`figsize`引数で図のサイズを指定可能 [27]。", "`plt.subplot(nrows, ncols, index)`：Figureをnrows x ncolsのグリッドに分割し、index番目の位置にAxesを作成（アクティブにする） [24]。\n    - indexは1から始まり、左上から右下へ数える。", "よりオブジェクト指向的なアプローチ：\n    - `fig, ax = plt.subplots()` (単一のAxes)\n    - `fig, axes = plt.subplots(nrows, ncols)` (複数のAxes、`axes`はAxesオブジェクトの配列) [28]。\n    - 各Axesオブジェクトに対してプロットメソッド (`ax.plot()`, `ax.set_xlabel()`など) を呼び出す [27]。"], explanation: "複数の関連するグラフを並べて表示したい場合、Matplotlibのサブプロット機能が役立ちます。Matplotlibの描画は、図全体を表す「Figure」オブジェクトと、その中の個々のグラフ描画領域を表す「Axes」オブジェクト（しばしばサブプロットと呼ばれる）で構成されます [24]。`plt.subplot()` 関数を使うと、Figureを指定した行数と列数のグリッドに分割し、その中の特定の位置に新しいAxesを作成（またはアクティブ化）して描画コマンドの対象とすることができます [24]。より柔軟で推奨される方法として、`plt.subplots()` 関数があります。これはFigureオブジェクトと、一つまたは複数のAxesオブジェクト（配列として）を同時に返します [28]。このAxesオブジェクトのメソッド（例: `ax.plot()`, `ax.set_title()`）を使って各サブプロットを個別に操作することで、より複雑なレイアウトの図も作成できます [27]。", exerciseHint: "2行1列のサブプロットを作成する。上のサブプロットにsin(x)のグラフを、下のサブプロットにcos(x)のグラフをそれぞれ描画する。各サブプロットに適切なタイトルを付ける。" },
                { title: "Unit 5.6: グラフの保存", goal: "作成したグラフを画像ファイルとして保存できるようになる。", topics: ["`plt.savefig('filename.png')`：現在のFigureを指定したファイル名で保存。", "対応フォーマット：PNG, JPG, PDF, SVGなど。ファイル名の拡張子で自動判別されることが多い。", "主要な引数：\n    - `dpi`：解像度 (dots per inch)。\n    - `bbox_inches='tight'`：余白を適切にトリミング。\n    - `transparent=True`：背景を透明にする。", "`plt.show()` の前に `plt.savefig()` を呼び出すことが推奨される場合がある。"], explanation: "作成したグラフは、レポートに貼り付けたり、プレゼンテーションで使用したりするために、画像ファイルとして保存する必要がよくあります。Matplotlibでは `plt.savefig()` 関数を使って、現在のFigureの内容を様々な形式のファイル（PNG, JPG, PDF, SVGなど）で保存できます。ファイル名は引数として指定し、通常、拡張子によってファイル形式が自動的に決定されます。`dpi` 引数で画像の解像度を指定したり、`bbox_inches='tight'` で図の周囲の余白を自動的に調整したりするなど、保存時のオプションもいくつか用意されています。一般的に、`plt.show()` を呼び出すとFigureの状態がリセットされることがあるため、グラフをファイルに保存する場合は `plt.show()` の前に `plt.savefig()` を実行することが推奨されます。", exerciseHint: "これまでに作成したグラフ（例：ラベルやタイトルが付いたsin/cosグラフ）を、`my_plot.png` という名前でPNGファイルとして保存する。保存された画像ファイルを開いて確認する。" }
            ]
        },
        {
            title: "第6章: scikit-learn基礎",
            summary: "この章では、Pythonの代表的な機械学習ライブラリであるscikit-learnの基本的な使い方を学びます [29, 30]。scikit-learnは、分類、回帰、クラスタリング、次元削減、モデル選択、前処理など、機械学習のためのシンプルで効率的なツールを幅広く提供しています [31]。この章を通じて、scikit-learnの基本的なAPI設計（Estimatorオブジェクト）、データセットの準備、モデルの訓練と評価という、機械学習の基本的なワークフローを体験します。",
            units: [
                { title: "Unit 6.1: scikit-learnとは？機械学習の基本的な流れ", goal: "scikit-learnライブラリの概要と、機械学習プロジェクトの一般的な流れを理解する。", topics: ["scikit-learnの紹介：Pythonで機械学習を実装するための包括的ライブラリ [29, 32]。", "提供機能：分類、回帰、クラスタリング、次元削減、モデル選択、前処理など [31]。", "機械学習の基本的な流れ [33, 34]：\n    1.  データセットの準備（特徴量Xとターゲットyの分離）。\n    2.  データの分割（訓練データとテストデータ）。\n    3.  モデルの選択とインスタンス化。\n    4.  モデルの訓練 (`fit()`メソッド)。\n    5.  モデルによる予測 (`predict()`メソッド)。\n    6.  モデルの評価。", "教師あり学習と教師なし学習の概念 [29]。"], explanation: "scikit-learnは、NumPy, SciPy, Matplotlibを基盤として構築された、オープンソースの機械学習ライブラリです [32]。その使いやすいAPIと豊富なアルゴリズム、充実したドキュメントにより、初心者から専門家まで幅広く利用されています。scikit-learnを使った機械学習の典型的なワークフローは、まず分析対象のデータセットを準備し、それをモデルの学習に使用する「訓練データ」と、学習済みモデルの性能を評価するための「テストデータ」に分割することから始まります [34]。次に、解きたい問題の種類（分類、回帰など）に応じて適切な機械学習モデルを選択し、そのインスタンスを作成します。そして、訓練データを使ってモデルを「訓練」（学習）し、学習済みモデルを使ってテストデータに対する「予測」を行い、その予測結果がどれだけ正確であったかを「評価」します [33, 34]。scikit-learnはこの一連の流れを統一的なインターフェースでサポートしています。", exerciseHint: "scikit-learnの公式ドキュメントやチュートリアルページを訪れ、どのような種類の機械学習アルゴリズムが提供されているか概要を眺めてみる [29]。" },
                { title: "Unit 6.2: データセットの準備 (トイデータセット、特徴量とターゲット)", goal: "scikit-learnに付属するトイデータセットを読み込み、機械学習で用いられる特徴量 (X) とターゲット (y) の形式を理解する。", topics: ["scikit-learnのトイデータセット：学習用に便利なサンプルデータセット。\n    - 例：アヤメ (iris) データセット [34]、ボストン住宅価格データセット、手書き数字データセット (digits)。\n    - `sklearn.datasets`モジュールからロード (`load_iris()`, `load_digits()`など)。", "データセットオブジェクトの属性：\n    - `data`：特徴量のNumPy配列 (X)。通常、各行がサンプル、各列が特徴量。\n    - `target`：ターゲット変数（目的変数、ラベル）のNumPy配列 (y)。\n    - `feature_names`：特徴量の名前。\n    - `target_names`：ターゲット変数のカテゴリ名（分類の場合）。\n    - `DESCR`：データセットの説明。", "特徴量 (X) とターゲット (y) の分離の重要性。"], explanation: "機械学習アルゴリズムを学ぶ際には、実際に動作を確認できるデータセットが必要です。scikit-learnは、`sklearn.datasets`モジュールを通じて、いくつかの有名な「トイデータセット」を提供しています [34]。これらは、アヤメの花の種類分類（iris）、手書き数字認識（digits）など、機械学習の入門でよく使われるデータセットです。これらのデータセットは通常、`data`属性（特徴量を格納したNumPy配列、慣習的に`X`と書かれる）と、`target`属性（予測したい値を格納したNumPy配列、慣習的に`y`と書かれる）を持っています。`X`の各行が一つのサンプル（データ点）を表し、各列がそのサンプルの特徴（属性）を表します。`y`は各サンプルに対応する正解ラベルや数値です。機械学習モデルは、この`X`と`y`の関係性を学習します。", exerciseHint: "`from sklearn.datasets import load_iris` を実行し、`iris = load_iris()` でアヤメデータセットをロードする。`iris.data` (X), `iris.target` (y), `iris.feature_names`, `iris.target_names`, `iris.DESCR` の内容を確認する。`X`と`y`の形状 (`shape`) を表示する。" },
                { title: "Unit 6.3: 訓練データとテストデータへの分割", goal: "データセットを訓練用とテスト用に分割する必要性を理解し、`train_test_split`関数を使って分割できるようになる。", topics: ["データ分割の目的：モデルの汎化性能（未知のデータに対する性能）を評価するため [34]。", "訓練データ (Training data)：モデルの学習に使用するデータ。", "テストデータ (Test data)：学習済みモデルの性能評価に使用する、学習には使わなかったデータ。", "`sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)`関数 [34]。\n    - `X`, `y`：分割対象の特徴量とターゲット。\n    - `test_size`：テストデータの割合（例: 0.2は20%）。`train_size`も指定可能。\n    - `random_state`：乱数シードの固定。結果の再現性を確保するため [34]。\n    - `stratify`：層化サンプリング。分類問題でクラスの比率を保ちたい場合に指定（例: `stratify=y`）。"], explanation: "機械学習モデルを構築する際、手元にあるデータ全てを学習に使ってしまうと、そのモデルが本当に新しい未知のデータに対しても上手く機能するのか（汎化性能）を正しく評価できません。モデルが学習データに過剰に適合してしまい（過学習）、訓練データでは高い性能を示すものの、新しいデータでは全くダメ、ということが起こり得ます。これを避けるため、データセットを「訓練データ」と「テストデータ」の2つに分割します [34]。モデルは訓練データのみを使って学習し、学習が完了した後、テストデータを使ってその性能を評価します。scikit-learnの `train_test_split` 関数は、この分割を簡単に行うためのユーティリティです。`test_size`でテストデータの割合を指定し、`random_state`で分割のランダム性を固定することで、実験の再現性を確保できます [34]。", exerciseHint: "前のユニットでロードしたアヤメデータセットの `X` と `y` を、`train_test_split` を使って訓練データ (X_train, y_train) とテストデータ (X_test, y_test) に分割する（テストデータの割合は30%、`random_state`は任意の値で固定）。それぞれの形状を確認する。" },
                { title: "Unit 6.4: モデルの選択と訓練 (例: ロジスティック回帰)", goal: "scikit-learnのEstimatorの概念を理解し、簡単な分類モデル（ロジスティック回帰）をインスタンス化し、訓練データで訓練できるようになる。", topics: ["Estimator (推定器)：scikit-learnにおけるモデルの総称。統一されたインターフェース (`fit()`, `predict()`など) を持つ。", "モデルの選択：解きたい問題の種類（分類、回帰など）に応じて適切なモデルを選択。", "例：ロジスティック回帰 (分類問題用) - `sklearn.linear_model.LogisticRegression` [34, 35]。", "モデルのインスタンス化：`model = LogisticRegression()`。ハイパーパラメータを指定することも可能。", "モデルの訓練：`model.fit(X_train, y_train)` [34]。\n    - `fit`メソッドはモデル内部の状態（学習されたパラメータ）を変更する。"], explanation: "scikit-learnでは、機械学習のアルゴリズムは「Estimator（推定器）」と呼ばれるオブジェクトとして実装されています。これらのEstimatorは、データの学習（訓練）を行うための `fit()` メソッドや、学習済みモデルを使って予測を行うための `predict()` メソッドなど、共通のインターフェースを持っています。これにより、異なるアルゴリズムでも同じような手順で扱うことができます。まず、解きたいタスク（例えば、アヤメの種類を分類する）に適したモデルクラス（例えば、`LogisticRegression`）を選択します [34, 35]。次に、そのクラスからモデルのインスタンスを作成します（例: `model = LogisticRegression()`）。この際、モデルの挙動を制御する「ハイパーパラメータ」（例えば、正則化の強さなど）を指定することもできます。そして、作成したモデルの `fit()` メソッドに訓練データ (`X_train`, `y_train`) を渡すことで、モデルの学習が実行されます [34]。`fit()` メソッドの実行により、モデルはデータからパターンを学習し、内部のパラメータが調整されます。", exerciseHint: "`from sklearn.linear_model import LogisticRegression` を実行。`model = LogisticRegression(max_iter=200)` のようにロジスティック回帰モデルをインスタンス化する（`max_iter`は収束計算の最大反復回数、デフォルト値で警告が出る場合があるため指定）。前のユニットで作成した `X_train` と `y_train` を使ってモデルを `fit()` する。" },
                { title: "Unit 6.5: 予測と評価 (例: 正解率)", goal: "訓練済みモデルを使ってテストデータに対する予測を行い、簡単な評価指標（正解率）でモデルの性能を評価できるようになる。", topics: ["テストデータによる予測：`y_pred = model.predict(X_test)` [34]。\n    - `predict()`メソッドは、学習済みモデルを使って新しいデータ (X_test) に対する予測結果 (y_pred) を返す。", "モデルの評価：予測結果 (y_pred) と実際の正解ラベル (y_test) を比較。", "分類問題の評価指標の例：正解率 (Accuracy)。\n    - `sklearn.metrics.accuracy_score(y_test, y_pred)` [34]。\n    - `model.score(X_test, y_test)` でも計算可能（分類器の場合、デフォルトで正解率）。", "他の評価指標の紹介（混同行列、適合率、再現率、F1スコアなど - 詳細はこの基礎編では扱わない）。"], explanation: "モデルの学習が完了したら、そのモデルがどれだけうまく機能するかを評価する必要があります。この評価は、学習には使用しなかったテストデータ (`X_test`) を使って行います。学習済みモデルの `predict()` メソッドに `X_test` を渡すと、各テストサンプルに対する予測結果 (`y_pred`) が得られます [34]。次に、この予測結果 `y_pred` と実際の正解ラベル `y_test` を比較して、モデルの性能を評価します。分類問題で最も基本的な評価指標の一つが「正解率（Accuracy）」で、これは全テストサンプルのうち、正しく分類されたサンプルの割合を示します。scikit-learnでは、`sklearn.metrics.accuracy_score()` 関数や、モデル自身の `score()` メソッドを使って簡単に正解率を計算できます [34]。正解率以外にも様々な評価指標がありますが、まずはこの基本的な評価の流れを理解することが重要です。", exerciseHint: "前のユニットで訓練したロジスティック回帰モデルを使って、`X_test` に対する予測 `y_pred` を行う。`accuracy_score(y_test, y_pred)` を使ってモデルの正解率を計算し表示する。" },
                { title: "Unit 6.6: (補足) 特徴量のスケーリングの重要性", goal: "機械学習アルゴリズムによっては特徴量のスケーリングが重要である理由を理解し、簡単なスケーリング手法（StandardScaler）の存在を知る。", topics: ["特徴量のスケール（値の範囲）が異なると問題が生じるアルゴリズムがある（例：距離ベースのアルゴリズム、勾配降下法を用いるアルゴリズム）。", "スケーリングの目的：全特徴量を同等のスケールに揃えることで、モデルの学習を安定させたり、性能を向上させたりする。", "代表的なスケーリング手法：\n    - 標準化 (Standardization)：平均を0、標準偏差を1にする。`sklearn.preprocessing.StandardScaler` [33]。\n        - `scaler = StandardScaler()`\n        - `scaler.fit(X_train)` (訓練データで平均と標準偏差を計算)\n        - `X_train_scaled = scaler.transform(X_train)`\n        - `X_test_scaled = scaler.transform(X_test)` (訓練データで計算した統計量を使ってテストデータも変換)\n    - 正規化 (Normalization / Min-Max Scaling)：値を0から1の範囲に変換。`sklearn.preprocessing.MinMaxScaler`。", "スケーラーは訓練データで `fit` し、その情報を使って訓練データとテストデータの両方を `transform` することが重要。"], explanation: "多くの機械学習アルゴリズム、特に特徴量間の距離を計算したり、勾配法でパラメータを更新したりするアルゴリズム（例えば、サポートベクターマシン、ニューラルネットワーク、ロジスティック回帰など）は、入力特徴量のスケール（値の範囲）が大きく異なると、学習がうまくいかなかったり、特定の特徴量の影響が過大/過小評価されたりする可能性があります。これを避けるために、学習前に特徴量のスケールを揃える「スケーリング」という前処理がしばしば行われます [33]。代表的な手法に、各特徴量を平均0、標準偏差1に変換する「標準化」（`StandardScaler`を使用）や、値を0から1の範囲に収める「正規化」（`MinMaxScaler`を使用）があります。重要なのは、スケーリングのための統計量（平均、標準偏差、最小値、最大値など）は訓練データのみから計算し、その統計量を使って訓練データとテストデータの両方を変換するという点です。これにより、テストデータからの情報漏洩を防ぎ、モデルの汎化性能を正しく評価できます。", exerciseHint: "アヤメデータセット `X_train` と `X_test` に対して `StandardScaler` を使って標準化を行い、変換後のデータの平均と標準偏差が（訓練データにおいて）およそ0と1になっていることを確認する（`X_train_scaled.mean(axis=0)` など）。" }
            ]
        },
        {
            title: "第7章: PyTorch基礎",
            summary: "この章では、Pythonの代表的な深層学習フレームワークであるPyTorchの基本的な概念と使い方を学びます [36, 37]。PyTorchは、柔軟性と使いやすさから研究者や開発者に広く支持されており、特にニューラルネットワークの構築と訓練に強力な機能を提供します。この章では、PyTorchの基本データ構造であるテンソル、自動微分機能 (Autograd)、ニューラルネットワーク構築のための `nn.Module` といった中核的な要素に焦点を当てます。",
            units: [
                { title: "Unit 7.1: PyTorchとは？テンソルの概要", goal: "PyTorchフレームワークの役割と、基本的なデータ構造であるテンソルの概念、作成方法を理解する。", topics: ["PyTorchの紹介：オープンソースの機械学習ライブラリ。特に深層学習で強力 [36, 38]。\n    - 主な特徴：NumPyに似たテンソル演算（GPUサポートあり）、柔軟な自動微分機能 [36]。", "テンソル (Tensor)：PyTorchにおける基本的なデータ構造。NumPyのndarrayに非常に似た多次元配列 [36]。\n    - スカラー (0階テンソル)、ベクトル (1階テンソル)、行列 (2階テンソル)、高階テンソル。", "テンソルの作成：\n    - PythonリストやNumPy配列から：`torch.tensor()`。\n    - 特定の形状と値で作成：`torch.zeros(shape)`, `torch.ones(shape)`, `torch.rand(shape)`。", "テンソルの属性：`shape`, `dtype`, `device` (CPU or GPU)。", "`import torch` の慣習。"], explanation: "PyTorchは、FacebookのAI研究グループによって開発された、Pythonベースのオープンソース機械学習ライブラリです。特にニューラルネットワークを用いた深層学習の分野で広く使われています [36, 38]。PyTorchの二大特徴は、GPU上での高速計算が可能な多次元配列「テンソル」と、ニューラルネットワークの勾配計算を自動で行う「自動微分（Autograd）」機能です [36]。テンソルは、NumPyの`ndarray`と概念的にも操作感的にも非常に似ており、スカラー、ベクトル、行列、さらに高次元のデータを表現できます。PythonのリストやNumPy配列から簡単にテンソルを作成できるほか、特定の値（0や1など）や乱数で初期化されたテンソルを生成する関数も用意されています。テンソルは、その形状 (`shape`)、データ型 (`dtype`)、そしてどのデバイス（CPUまたはGPU）に配置されているか (`device`) といった属性を持ちます。", exerciseHint: "`import torch` を実行する。Pythonのリスト `[[1,2],[3,4]]` から2x2のテンソルを作成し、その `shape`, `dtype`, `device` を表示する。`torch.rand(3, 2)` で乱数テンソルを作成する。" },
                { title: "Unit 7.2: テンソルの基本操作とNumPyとの連携", goal: "PyTorchテンソルの基本的な算術演算、インデックス参照、スライシング操作を習得し、NumPy配列との相互変換ができるようになる。", topics: ["算術演算：要素ごとの加算、減算、乗算、除算など (NumPyと同様)。\n    - 例：`tensor1 + tensor2`, `tensor * 2`。", "インデックス参照とスライシング：NumPy配列と同様の操作が可能。\n    - 例：`tensor[0, 0]`, `tensor[:, 1]`。", "形状変更：`view()` (NumPyの`reshape`に類似、メモリを共有することが多い), `reshape()`。", "NumPy配列との相互変換：\n    - NumPy配列からPyTorchテンソルへ：`torch.from_numpy(numpy_array)`。\n    - PyTorchテンソルからNumPy配列へ：`tensor.numpy()`。\n    - これらはメモリを共有する場合があるため注意（一方を変更すると他方も変わる）。CPU上のテンソルのみNumPyに変換可能。"], explanation: "PyTorchのテンソルは、NumPyの`ndarray`と非常によく似た操作感で扱うことができます。要素ごとの算術演算（足し算、掛け算など）や、インデックスとスライスを使った要素へのアクセス方法はNumPyとほぼ同じです。テンソルの形状を変更するための`view()`メソッド（NumPyの`reshape`に似ていますが、多くの場合メモリを共有し、連続したメモリ領域を要求します）や`reshape()`メソッドも提供されています。PyTorchの大きな利点の一つは、既存のNumPyコードとの連携が容易であることです。`torch.from_numpy()`関数でNumPy配列をPyTorchテンソルに変換でき、テンソルの`.numpy()`メソッドでPyTorchテンソルをNumPy配列に変換できます。多くの場合、これらの変換ではメモリが共有されるため、非常に効率的ですが、一方のオブジェクトの値を変更するともう一方も変更される点には注意が必要です。また、GPU上にあるテンソルをNumPy配列に変換するには、一度CPUに移動させる（`.cpu()`メソッド）必要があります。", exerciseHint: "2つの簡単なPyTorchテンソルを作成し、加算と乗算を行う。作成したテンソルの一つをNumPy配列に変換し、その値を変更して元のPyTorchテンソルも変わるか確認する（メモリ共有の場合）。" },
                { title: "Unit 7.3: 自動微分 (Autograd) の基礎", goal: "PyTorchの自動微分機能 (Autograd) の役割を理解し、テンソルの勾配を計算する基本的な方法を習得する。", topics: ["自動微分の必要性：ニューラルネットワークの学習（誤差逆伝播法）における勾配計算の自動化 [36]。", "`requires_grad`属性：テンソルが勾配計算の対象であるかを示すブール値。デフォルトは`False`。\n    - `tensor.requires_grad_(True)` で設定。", "計算グラフの概念：演算の繋がりを記録し、勾配計算に利用 [36]。", "`backward()`メソッド：スカラー値のテンソル（通常は損失関数L）に対して呼び出すと、計算グラフを遡って `requires_grad=True` のテンソルに関するLの勾配を計算 [39]。", "`grad`属性：`backward()`実行後、各テンソルの勾配が `tensor.grad` に格納される [39]。", "勾配計算を行わないコンテキスト：`with torch.no_grad():` ブロック内では計算グラフが構築されない（推論時やパラメータ更新時に使用）[39, 40]。"], explanation: "ニューラルネットワークの学習では、損失関数の値を最小化するようにモデルのパラメータ（重みやバイアス）を更新します。この更新量を決定するためには、損失関数を各パラメータで偏微分した「勾配」を計算する必要があります。PyTorchのAutograd機能は、この複雑な勾配計算を自動的に行ってくれます [36, 41]。テンソルを作成する際に `requires_grad=True` を設定すると、そのテンソルに対する全ての演算が追跡され、「計算グラフ」が構築されます。この計算グラフは、入力から出力（通常は損失）までの演算の連鎖を表します。最終的なスカラー出力（損失）に対して `.backward()` メソッドを呼び出すと、PyTorchはこのグラフを逆方向に辿り、途中の各テンソル（`requires_grad=True`が設定されたもの）に関する勾配を計算し、それぞれの `.grad` 属性に格納します [39]。これにより、開発者は手動で微分式を導出する手間から解放され、モデル構築に集中できます。モデルの推論時や学習済みパラメータを更新する際には、勾配計算が不要なため `with torch.no_grad():` ブロックを使用します [39]。", exerciseHint: "`x = torch.tensor([2.0], requires_grad=True)` と `w = torch.tensor([3.0], requires_grad=True)` を作成。`y = w * x`、`z = y * y` を計算。`z.backward()` を実行し、`x.grad` と `w.grad` の値を表示して、手計算での偏微分値 ($dz/dx = 2w^2x$, $dz/dw = 2wx^2$) と一致するか確認する。" },
                { title: "Unit 7.4: ニューラルネットワークの構築 (nn.Module)", goal: "PyTorchの `torch.nn.Module` を使って簡単なニューラルネットワークモデルを定義する方法の基本を理解する。", topics: ["`torch.nn`パッケージ：ニューラルネットワーク構築のためのモジュールやクラスを提供 [36]。", "`nn.Module`：全てのニューラルネットワークモジュールの基底クラス。\n    - カスタムモデルは `nn.Module` を継承して作成。\n    - `__init__()`メソッド：層（レイヤー）などのコンポーネントを定義。\n        - 例：`nn.Linear(in_features, out_features)` (全結合層)。\n        - 例：`nn.ReLU()` (活性化関数)。\n    - `forward()`メソッド：順伝播の計算処理を定義。入力テンソルを受け取り、出力テンソルを返す。", "簡単なモデル定義の例（1層の線形モデルなど）。"], explanation: "PyTorchでニューラルネットワークを構築する際には、`torch.nn` パッケージが中心的な役割を果たします [36]。このパッケージには、様々な種類の層（全結合層、畳み込み層など）、活性化関数、損失関数などが定義されています。カスタムのニューラルネットワークモデルは、通常 `nn.Module` クラスを継承して作成します。`nn.Module` を継承したクラスでは、主に2つのメソッドをオーバーライド（再定義）します。一つはコンストラクタである `__init__()` メソッドで、ここではモデル内で使用する層（例えば `nn.Linear` で定義される全結合層や `nn.ReLU` などの活性化関数）をインスタンス化し、属性として保持します。もう一つは `forward()` メソッドで、ここに入力データがモデルを通過する際の計算（順伝播）のロジックを記述します。この `forward()` メソッドが、入力テンソルを受け取って出力テンソルを返す実際の処理を定義します。このように `nn.Module` を使うことで、複雑なネットワーク構造もモジュール的に、整理された形で定義することができます [42]。", exerciseHint: "`import torch.nn as nn` を実行。`nn.Module` を継承した簡単な線形モデルクラスを定義する。`__init__` で `nn.Linear(10, 1)` のような全結合層を一つ定義し、`forward` メソッドで入力にこの層を適用して返すように記述する。モデルをインスタンス化し、適当な入力テンソル（例：`torch.rand(1, 10)`）を与えて出力を確認する。" },
                { title: "Unit 7.5: 損失関数と最適化アルゴリズム", goal: "PyTorchで代表的な損失関数と最適化アルゴリズムを使用する基本的な方法を理解する。", topics: ["損失関数 (`torch.nn` モジュール内)：モデルの出力と正解ラベルとの間の誤差を測定する関数。\n    - 例：`nn.MSELoss()` (平均二乗誤差、回帰問題用)。\n    - 例：`nn.CrossEntropyLoss()` (クロスエントロピー誤差、多クラス分類問題用)。", "最適化アルゴリズム (`torch.optim` モジュール)：計算された勾配に基づいてモデルのパラメータを更新するアルゴリズム [36]。\n    - 例：`optim.SGD(model.parameters(), lr=0.01)` (確率的勾配降下法)。\n    - 例：`optim.Adam(model.parameters(), lr=0.001)`。\n    - `model.parameters()`：モデル内の学習対象パラメータをイテレータとして返す。\n    - `lr` (learning rate)：学習率。", "基本的な学習ループの流れ（概略）：\n    1.  `optimizer.zero_grad()`：前回の勾配情報をリセット。\n    2.  `outputs = model(inputs)`：モデルの順伝播。\n    3.  `loss = criterion(outputs, labels)`：損失の計算。\n    4.  `loss.backward()`：勾配の計算。\n    5.  `optimizer.step()`：パラメータの更新。"], explanation: "ニューラルネットワークの学習プロセスは、モデルの予測と実際の正解との間の「損失（誤差）」を計算し、その損失を最小化するようにモデルのパラメータを調整していく繰り返し作業です。PyTorchでは、様々な種類の損失関数が `torch.nn` モジュールに用意されています。例えば、回帰問題では平均二乗誤差（`nn.MSELoss`）、多クラス分類問題ではクロスエントロピー誤差（`nn.CrossEntropyLoss`）などがよく使われます。計算された損失に基づいてモデルのパラメータをどのように更新するかを決定するのが「最適化アルゴリズム」で、これは `torch.optim` モジュールで提供されます [36]。代表的なものにSGD（確率的勾配降下法）やAdamがあります。最適化アルゴリズムのインスタンスを作成する際には、更新対象のモデルパラメータ（`model.parameters()`で取得）と学習率（`lr`）などを指定します。典型的な学習ループでは、まず過去の勾配情報をリセットし（`optimizer.zero_grad()`）、モデルに入力を通して出力を得、損失を計算し、損失の勾配を計算し（`loss.backward()`）、最後に最適化アルゴリズムでパラメータを更新します（`optimizer.step()`）。", exerciseHint: "前のユニットで作成した線形モデルのインスタンス `model` を用意する。ダミーの入力 `inputs = torch.rand(5, 10)` と正解ラベル `labels = torch.rand(5, 1)` を作成する。損失関数 `criterion = nn.MSELoss()` とオプティマイザ `optimizer = torch.optim.SGD(model.parameters(), lr=0.01)` を定義する。学習ループの1ステップ（`optimizer.zero_grad()` から `optimizer.step()` まで）を実行してみる。" }
            ]
        }
    ],
    conclusion: {
        title: "まとめと今後の学習に向けて",
        content: `このカリキュラムでは、Jupyter Notebookの基本的な操作から始まり、データサイエンスのためのPythonの基礎、そしてpandas、NumPy、Matplotlibといったデータ処理・可視化ライブラリ、さらには機械学習ライブラリscikit-learn、深層学習フレームワークPyTorchの初歩までを網羅的に学びました。\n\n各章で習得した知識とスキルは、それぞれが独立しているだけでなく、相互に深く関連し合っています。このカリキュラムで扱った内容は、各ライブラリの広大な機能のごく一部に過ぎません。しかし、ここで得た基礎知識は、より高度なトピックや専門的な応用に進むための確かな足がかりとなるはずです。\n\nデータサイエンスと機械学習の分野は日進月歩で進化していますが、本カリキュラムで習得した基礎的な概念とツールを扱う能力は、その変化に対応していく上での普遍的な力となるでしょう。継続的な学習と実践を通じて、データから価値を生み出す能力を高めていってください。`
    }
};

const navElement = document.getElementById('curriculum-nav');
const mainContentArea = document.getElementById('main-content-area');
const contentPlaceholder = document.getElementById('content-placeholder');
let currentCharts = [];

function buildNavigation() {
    const introLi = document.createElement('li');
    const introLink = document.createElement('a');
    introLink.href = '#';
    introLink.textContent = curriculumData.introduction.title;
    introLink.className = 'block py-2 px-3 rounded hover:bg-teal-600 hover:text-white transition-colors';
    introLink.onclick = (e) => {
        e.preventDefault();
        displayIntroduction();
        setActiveLink(introLink);
    };
    introLi.appendChild(introLink);
    navElement.appendChild(introLi);

    curriculumData.chapters.forEach((chapter, chapterIndex) => {
        const chapterLi = document.createElement('li');
        const chapterTitle = document.createElement('div');
        chapterTitle.textContent = chapter.title;
        chapterTitle.className = 'font-semibold py-2 px-3 rounded cursor-pointer hover:bg-teal-600 hover:text-white transition-colors';
        chapterLi.appendChild(chapterTitle);

        const unitsUl = document.createElement('ul');
        unitsUl.className = 'ml-4 mt-1 space-y-1 hidden'; // Initially hidden

        chapter.units.forEach((unit, unitIndex) => {
            const unitLi = document.createElement('li');
            const unitLink = document.createElement('a');
            unitLink.href = '#';
            unitLink.textContent = unit.title;
            unitLink.className = 'block py-1 px-2 text-sm rounded hover:bg-teal-500 hover:text-white transition-colors';
            unitLink.onclick = (e) => {
                e.preventDefault();
                displayUnitContent(chapterIndex, unitIndex);
                setActiveLink(unitLink);
            };
            unitLi.appendChild(unitLink);
            unitsUl.appendChild(unitLi);
        });

        chapterLi.appendChild(unitsUl);
        navElement.appendChild(chapterLi);

        chapterTitle.onclick = () => {
            unitsUl.classList.toggle('hidden');
            chapterTitle.classList.toggle('bg-teal-600');
            chapterTitle.classList.toggle('text-white');
            if (!unitsUl.classList.contains('hidden')) {
                displayChapterSummary(chapterIndex);
                setActiveLink(chapterTitle); // Keep chapter title active if summary is shown
            }
        };
    });

    const conclusionLi = document.createElement('li');
    const conclusionLink = document.createElement('a');
    conclusionLink.href = '#';
    conclusionLink.textContent = curriculumData.conclusion.title;
    conclusionLink.className = 'block py-2 px-3 rounded hover:bg-teal-600 hover:text-white transition-colors';
    conclusionLink.onclick = (e) => {
        e.preventDefault();
        displayConclusion();
        setActiveLink(conclusionLink);
    };
    conclusionLi.appendChild(conclusionLink);
    navElement.appendChild(conclusionLi);
}

function setActiveLink(activeElement) {
    document.querySelectorAll('#curriculum-nav a, #curriculum-nav div[onclick]').forEach(el => {
        el.classList.remove('bg-teal-700', 'text-white', 'font-bold');
        if (el.parentElement.tagName === 'LI' && el.parentElement.parentElement.id === 'curriculum-nav') { // Chapter titles
             el.classList.remove('bg-teal-600'); // remove chapter title specific active style
        }
    });
    activeElement.classList.add('bg-teal-700', 'text-white', 'font-bold');
     if (activeElement.parentElement.tagName === 'LI' && activeElement.parentElement.parentElement.id === 'curriculum-nav' && activeElement.nextElementSibling && activeElement.nextElementSibling.tagName === 'UL') { // Chapter title
        activeElement.classList.add('bg-teal-600'); // Special active style for chapter title
        activeElement.classList.remove('bg-teal-700');
    }
}


function clearPreviousCharts() {
    currentCharts.forEach(chart => chart.destroy());
    currentCharts = [];
}

function displayIntroduction() {
    clearPreviousCharts();
    contentPlaceholder.innerHTML = `
        <h2 class="text-3xl font-bold text-teal-700 mb-4">${curriculumData.introduction.title}</h2>
        <div class="prose max-w-none">${curriculumData.introduction.content.replace(/\n/g, '<br>')}</div>
    `;
}

function displayChapterSummary(chapterIndex) {
    clearPreviousCharts();
    const chapter = curriculumData.chapters[chapterIndex];
    contentPlaceholder.innerHTML = `
        <h2 class="text-3xl font-bold text-teal-700 mb-4">${chapter.title}</h2>
        <p class="text-lg mb-6">${chapter.summary}</p>
        <h3 class="text-2xl font-semibold text-teal-600 mb-3">この章のユニット一覧：</h3>
        <ul class="list-disc pl-5 space-y-1">
            ${chapter.units.map((unit, unitIndex) => `<li><a href="#" onclick="event.preventDefault(); displayUnitContent(${chapterIndex}, ${unitIndex}); setActiveLink(document.querySelector('#curriculum-nav ul li ul li a[onclick*=\\"displayUnitContent(${chapterIndex}, ${unitIndex})\\"]'));" class="text-blue-600 hover:underline">${unit.title}</a></li>`).join('')}
        </ul>
    `;
}

function displayConclusion() {
    clearPreviousCharts();
    contentPlaceholder.innerHTML = `
        <h2 class="text-3xl font-bold text-teal-700 mb-4">${curriculumData.conclusion.title}</h2>
        <div class="prose max-w-none">${curriculumData.conclusion.content.replace(/\n/g, '<br>')}</div>
    `;
}

function formatTextWithCode(text) {
    // Basic regex to find backticks and replace with <code>, not handling nested or multiline
    // A more robust parser would be needed for complex cases
    // This will handle simple inline `code` examples.
    // For multiline, the Markdown input should ideally use <pre><code> or be structured.
    // The current data structure separates topics, so multi-line code is less likely in simple topic strings.
    // If present in explanation, it would need more careful handling or presumes HTML in source.
    // Given the source, it's mainly inline.
    return text.replace(/`([^`]+)`/g, '<code class="bg-stone-200 px-1 rounded text-sm font-mono text-red-700">$1</code>');
}

function displayUnitContent(chapterIndex, unitIndex) {
    clearPreviousCharts();
    const unit = curriculumData.chapters[chapterIndex].units[unitIndex];
    let topicsHtml = unit.topics.map(topic => `<li>${formatTextWithCode(topic)}</li>`).join('');
    // For multiline items within topics array (e.g. from Unit 1.3)
    topicsHtml = topicsHtml.replace(/\n\s*-/g, '<ul><li class="ml-4">').replace(/\n(?!<\/ul>)/g, '</li></ul><li class="ml-4">') // simplistic conversion, might need refinement
                  .replace(/<\/li><\/ul><li class="ml-4">/g, '</li><li class="ml-4">');


    contentPlaceholder.innerHTML = `
        <h2 class="text-3xl font-bold text-teal-700 mb-2">${unit.title}</h2>
        <hr class="mb-6">

        <section class="mb-6">
            <h3 class="text-xl font-semibold text-teal-600 mb-2">学習目標</h3>
            <p>${formatTextWithCode(unit.goal)}</p>
        </section>

        <section class="mb-6">
            <details class="bg-white p-4 rounded shadow">
                <summary class="text-xl font-semibold text-teal-600">主要トピック</summary>
                <ul class="list-disc pl-5 mt-2 space-y-1 prose max-w-none">
                    ${topicsHtml}
                </ul>
            </details>
        </section>

        <section class="mb-6">
            <details class="bg-white p-4 rounded shadow">
                <summary class="text-xl font-semibold text-teal-600">解説</summary>
                <div class="mt-2 prose max-w-none">${formatTextWithCode(unit.explanation).replace(/\n/g, '<br>')}</div>
            </details>
        </section>

        <section class="mb-6">
            <details class="bg-white p-4 rounded shadow">
                <summary class="text-xl font-semibold text-teal-600">演習のヒント</summary>
                <div class="mt-2 prose max-w-none">${formatTextWithCode(unit.exerciseHint).replace(/\n/g, '<br>')}</div>
            </details>
        </section>
        <div id="charts-area" class="mt-8 space-y-8"></div>
    `;

    if (unit.chartConfigs) {
        const chartsArea = document.getElementById('charts-area');
        unit.chartConfigs.forEach(config => {
            const chartWrapper = document.createElement('div');
            chartWrapper.className = 'bg-white p-4 rounded shadow';
            
            const chartTitleEl = document.createElement('h4');
            chartTitleEl.className = 'text-lg font-semibold text-teal-600 mb-3 text-center';
            chartTitleEl.textContent = config.title || 'サンプルグラフ';
            chartWrapper.appendChild(chartTitleEl);

            const chartContainer = document.createElement('div');
            chartContainer.className = 'chart-container';
            const canvas = document.createElement('canvas');
            canvas.id = config.id;
            chartContainer.appendChild(canvas);
            chartWrapper.appendChild(chartContainer);
            chartsArea.appendChild(chartWrapper);

            // Ensure options for Chart.js are well-defined
            const options = config.options || {};
            options.responsive = true;
            options.maintainAspectRatio = false;

            // Label wrapping logic for x-axis
            if (options.scales && options.scales.x && options.scales.x.ticks === undefined) {
                 options.scales.x.ticks = {};
            } else if (options.scales && options.scales.x === undefined) {
                 options.scales.x = { ticks: {} };
            } else if (options.scales === undefined) {
                options.scales = { x: { ticks: {} } };
            }
            
            options.scales.x.ticks.callback = function(value, index, values) {
                const label = this.getLabelForValue(value);
                if (typeof label === 'string' && label.length > 16) {
                    const parts = [];
                    for (let i = 0; i < label.length; i += 16) {
                        parts.push(label.substring(i, i + 16));
                    }
                    return parts;
                }
                return label;
            };
            
            // Label wrapping logic for y-axis (if needed)
            if (options.scales && options.scales.y && options.scales.y.ticks === undefined) {
                 options.scales.y.ticks = {};
            } else if (options.scales && options.scales.y === undefined) {
                 options.scales.y = { ticks: {} };
            } else if (options.scales === undefined && !options.scales.y) { // if scales exists but not y
                if(options.scales.x) options.scales.y = { ticks: {} };
                else options.scales = { y: { ticks: {} } }; // if scales doesn't exist at all
            }
             if (options.scales && options.scales.y && options.scales.y.ticks) {
                options.scales.y.ticks.callback = function(value, index, values) {
                    const label = this.getLabelForValue(value);
                    if (typeof label === 'string' && label.length > 16) {
                        const parts = [];
                        for (let i = 0; i < label.length; i += 16) {
                            parts.push(label.substring(i, i + 16));
                        }
                        return parts;
                    }
                    return label;
                };
            }


            const chart = new Chart(
                document.getElementById(config.id),
                {
                    type: config.type,
                    data: config.data,
                    options: options
                }
            );
            currentCharts.push(chart);
        });
    }
}


document.addEventListener('DOMContentLoaded', () => {
    buildNavigation();
    displayIntroduction(); // Show introduction by default
    const firstNavLink = document.querySelector('#curriculum-nav a');
    if (firstNavLink) {
        setActiveLink(firstNavLink);
    }
});

</script>
</body>
</html>
